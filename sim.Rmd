---
title: "Doubly Robust Estimator: simulation activity in R"
description: |
---

# Computational Simulation {#sim}

- *Goal*: estimate a causal effect when you do not have data from a randomized experiment 

- *Strategy 1*: Re-weighting each observation by the probability of receiving A or B so that the data approximates a randomized experiment 

- *Strategy 2*: Modelling the outcome directly with a linear regression

- *Combining Idea 1 and 2*: To form doubly robust estimator

---

```{r}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE, tidy = TRUE, cache= T)
```


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, 
        fig.align = "center")

library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
library(knitr)
library(gridExtra)
library(cowplot)
```

---

# Setting up data

We assign $X_1$ and $X_2$ as causal variables, and define a true ACE of 10.

```{r setting-up}
simu_observational_data <- function(simu_id = 1, n_obs) {
  X_1    <- rnorm(n_obs)
  X_2    <- rnorm(n_obs)
  XB     <- 0.2*X_1 + 0.2*X_2
  prob_A <- exp(XB) / (1 + exp(XB))
  A      <- rbinom(n_obs, 1, prob_A)
  
  # We set the causal effect of treatment A is 10
  Y      <- 100 + X_1 + X_2 + 10*A + rnorm(n_obs) 
  
  # summarize variables into a data frame
  data.frame(simu_id = simu_id, n_obs = n_obs, 
             var_1 = X_1, var_2 = X_2, 
             treatment = A, outcome = Y)  
} 
```

## IPW model

We create the correct model of IPW with both variables, $X_1$ and $X_2$.
```{r}
prop_score_model <- function(data) {
  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')
}
```

```{r}
#IPW estimator is correct
ipw_estimator <- function(data, model) {
  data %>% 
    mutate(
      prob = predict(model, newdata = data, type = 'response'),
    ) %>% 
    summarise(
      # Calculate expected value for both treatment and non-treatment using IPW equation
      EY0_ipw = mean(outcome*(1 - treatment) / (1 - prob)),
      EY1_ipw = mean(outcome*treatment / prob)
    ) %>% 
    # Calculate ACE
    mutate(ipw = EY1_ipw - EY0_ipw)
}
```

We miss $X_2$ in the model, which makes the model misspecified.
```{r}
prop_score_model_w <- function(data) {
  # OOPS! I forgot var_2
  glm(treatment ~ var_1, data = data, family = 'binomial')
}
```

```{r}
# IPW estimator is wrong
ipw_estimator_w <- function(data, model) {
  data %>% 
    mutate(
      prob = predict(model, newdata = data, type = 'response'),
    ) %>% 
    summarise(
      # Calculate expected value for both treatment and non-treatment using IPW equation
      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),
      EYA_ipw = mean(outcome*treatment / prob)
    ) %>% 
    # Calculate ACE
    mutate(ipw_w = EYA_ipw - EYB_ipw)
}
```

## REG model

We create the correct model of outcome regression model with both variables, $X_1$ and $X_2$.
```{r}
mean_outcome_model <- function(data) {
  glm(outcome ~ treatment + var_1 + var_2, data = data)
}
```

```{r}
#REG estimator is correct
outcome_model_estimator <- function(data) {
   mean_model <- mean_outcome_model(data) # Compute the model
   summary(mean_model)$coefficients['treatment', ][1] # Coefficient for treatment
}
```

We miss $X_2$ in this model, which makes this REG model misspecified.
```{r}
mean_outcome_model_w <- function(data) {
  # MISSING var_2??!?!
  glm(outcome ~ var_1 + treatment, data = data)
}
```

```{r}
# REG estimator is wrong
outcome_model_estimator_w <- function(data) {
   mean_model <- mean_outcome_model_w(data) # Compute the model
   summary(mean_model)$coefficients['treatment', ][1] # Coefficient for treatment
}
```

## DRE estimator

Building DRE estimator using the combination of IPW model and REG model.
```{r}
dr_estimator <- function(data, prop_model, mean_model) {
  data %>% 
    mutate(
      # IPW model
      prob = predict(prop_model, newdata = data, type = 'response'), 
      # REG model 
      pred = predict(mean_model, newdata = data, type = 'response'),
      # Combination of IPW and REG model
      augm = (treatment - prob)*pred
    ) %>% 
    summarise(
      # Calculate expected value for both treatment and non-treatment using IPW + REG.
      EY0_dr = mean((outcome*(1 - treatment) - augm) / (1 - prob)),
      EY1_dr = mean((outcome*treatment - augm) / prob)
    ) %>% 
    # Compute ACE for DRE
    mutate(dre = EY1_dr - EY0_dr)
}
```

Then, we create the simulated dataset for all estimators and expected value from IPW, REG, and DRE models. 
```{r, include=FALSE}
n_simu <- 150
n_obs <- 200

nested_df <- 
  purrr::map2_dfr(1:n_simu, rep(n_obs, n_simu), simu_observational_data) %>% 
  group_by(simu_id) %>% 
  nest() %>% 
  mutate(
    # correct ipw model
    prop_model     = map(data, prop_score_model),
    # incorrect ipw model
    prop_model_w   = map(data, prop_score_model_w),
    # correct reg model
    mean_model     = map(data, mean_outcome_model),
    # incorrect reg model
    mean_model_w   = map(data, mean_outcome_model_w),
    # correct reg estimation
    model_estimate = map(data, outcome_model_estimator),
    # incorrect reg estimation
    model_estimate_w = map(data, outcome_model_estimator_w),
    # correct ipw estimation
    ipw_estimate   = map2(data, prop_model, ipw_estimator),
    # incorrect ipw estimation
    ipw_estimate_w = map2(data, prop_model_w, ipw_estimator_w),
    # generate dre estimation
    dr_estimate    = pmap(list(data, prop_model, mean_model), dr_estimator)
  ) %>% 
  ungroup() %>% 
  unnest(c(model_estimate, model_estimate_w, ipw_estimate, ipw_estimate_w, dr_estimate))
```

Now, we have five models: IPW (both correct and incorrect), REG (both correct and incorrect), and DRE.

---

# Strategy 1: Inverse Probability Weighting (IPW)

## Intuition Behind it

- In an experiment the probability of receiving a treatment are always equal across all units (50%)

- In the current case, the probability of receiving the treatment depends on variables that affect the outcome

- If we knew what this probabilities are we could re-weight our sample such that the data would better match a randomized experiment - by creating the "pesudopopulation" (mentioned earlier)

- Reminder: propensity score is just a logistic regression of the probability of receiving the treatment, giving their $Z$ values (confounders)

In our example, we proposed the correct IPW model:

```{r, eval = FALSE}
prop_score_model <- function(data) {
  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')
}
```

## Introducing IPW estimator

- Similar to a difference of means but weights each observation inversely proportional to its probability of receiving a treatment (propensity score $\widehat {PS_i}$)

$$\hat{\delta}_{IPW} = \frac{1}{n}\sum_{i=1}^{n}\bigg[\frac{E[Y_{i}|{A=1}]}{\color{red}{\widehat {PS_i}}} - \frac{E[Y_{i}|{A=0}]}{\color{red}{1-\widehat {PS_i}}}\bigg]$$

Generating IPW estimator and calculate ACE by IPW equation:

```{r, eval = FALSE}
ipw_estimator <- function(data, model) {
  data %>% 
    mutate(
      prob = predict(model, newdata = data, type = 'response'),
    ) %>% 
    summarise(
      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),
      EYA_ipw = mean(outcome*treatment / prob)
    ) %>% 
    mutate(ipw = EYA_ipw - EYB_ipw)
}
```


## IPW Performance 

Plot for correct IPW
```{r, echo = FALSE}
mean_ipw_estimator <- 
  mean(nested_df$ipw)

nested_df %>% 
  ggplot(aes(x = simu_id, y = ipw)) +
  ggtitle(paste('The mean of the ipw estimate (correctly specified) is ', round(mean_ipw_estimator, 2))) + 
  geom_point(color = 'blue') +
  geom_hline(yintercept = 10) + ylab("ACE estimate")+
  theme_bw()
```

The plot shows the data points are evenly spread around 10, and the mean of correct IPW estimate is 10.07, which is close to the true ACE we set. 

## IPW could fail

- If the model for A is incorrect, it would cause bias in the IPW, which cause IPW to fail. We used the biased ipw results from the 'nested_df' dataset.

```{r, echo = FALSE}
mean_ipw_estimator_w <- 
  mean(nested_df$ipw_w)

nested_df %>% 
  ggplot(aes(x = simu_id, y = ipw_w)) +
  ggtitle(paste('The mean of the ipw estimate (incorrectly specified) is ', round(mean_ipw_estimator_w, 2))) + 
  geom_point(color = 'blue') +
  geom_hline(yintercept = 10) +ylab("ACE estimate")+
  theme_bw()

```

The plot shows a obvious trend that all data points from biased IPW model shift upward, which the ACE for incorrect IPW model is higher than the ACE=10 we set in the beginning.  

```{r, echo=F}
a <- ggplot(nested_df, aes(x=simu_id, y=ipw, group=1)) +
  geom_boxplot()+
  geom_hline(yintercept=10, color='red')+ylab("ACE estimate")+
  ylim(7, 13.5)

b <- ggplot(nested_df, aes(x=simu_id, y=ipw_w, group=1))+
  geom_boxplot()+
  geom_hline(yintercept=10, color='red')+ylab("ACE estimate")+
  ylim(7, 13.5)

plot_grid(a, b, labels=c("Correct IPW", "Incorrect IPW"), ncol = 2, nrow = 1)
```

We overestimated the true ACE (which is 10) if we wrongly specified the model form in IPW setting.

---

# Strategy 2: REG estimator (model the outcome)

The same (correct) REG model as we've seen before:

```{r, eval = FALSE}
mean_outcome_model <- function(data) {
  glm(outcome ~ var_1 + var_2 + treatment, data = data)
}
```

```{r, eval = FALSE}
outcome_model_estimator <- function(data) {
   mean_model <- mean_outcome_model(data)
   summary(mean_model)$coefficients['treatment', ][1]
}
```

## REG Performance

```{r, echo = FALSE}
mean_model_estimator <- 
  mean(nested_df$model_estimate)

nested_df %>% 
  ggplot(aes(x = simu_id, y = model_estimate)) +
  ggtitle(paste('The mean of the REG estimate (correctly specified) is ', round(mean_model_estimator, 2))) + 
  geom_point(color = 'blue') +
  geom_hline(yintercept = 10) +ylab("ACE estimate")+
  theme_bw()
```

When outcome model is correctly modelled, this shows unbiased estimation of ACE.

## REG could also fail

- If the model for Y is incorrect (as we recalled we left *var_2* out), it will cause bias in the REG outcome model, which cause the model to fail.

```{r, echo=F}
mean_model_estimator_w <- 
  mean(nested_df$model_estimate_w)

nested_df %>% 
  ggplot(aes(x = simu_id, y = model_estimate_w)) +
  ggtitle(paste('The mean of the REG estimate (incorrectly specified) is ', round(mean_model_estimator_w, 2))) + 
  geom_point(color = 'blue') +
  geom_hline(yintercept = 10) +ylab("ACE estimate")+
  theme_bw()
```

```{r, echo=F}
c <- ggplot(nested_df, aes(x=simu_id, y=model_estimate, group=1)) +
  geom_boxplot()+geom_hline(yintercept=10, color='red')+ylab("ACE estimate")+
  ylim(9, 11)
d <- ggplot(nested_df, aes(x=simu_id, y=model_estimate_w, group=1))+
  geom_boxplot()+geom_hline(yintercept=10, color='red')+ylab("ACE estimate")+
  ylim(9, 11)

plot_grid(c, d, labels=c("Correct REG", "Incorrect REG"), ncol = 2, nrow = 1)
```

We also overestimated the true ACE (10) if our REG model is mis-specified.


---

# Combining Strategy 1 and 2

- If the propensity score model is incorrect, strategy 1 will not work

- If the outcome model is incorrect, strategy 2 will not work

- If you combine both approaches, you just need either one to work but not both

- This is "doubly robust" property!

## Doubly Robust Estimator

DRE's estimation of average causal effect can be summarized into this equation (it is the same thing as the one in the previous section but we changed some notations):

$$\hat{\delta}_{DRE} = \frac{1}{n}\sum_{i=1}^{n}\bigg[\frac{Y_{i}A_{i} -\color{red}{(A_i-\pi(Z_{i}))\mu(Z_i, A_i)}}{\pi(Z_{i})} - \frac{Y_{i}(1-A_{i}) -\color{red}{(A_i-\pi(Z_{i}))\mu(Z_i, A_i)}}{1-\pi(Z_{i})}\bigg]$$

where $\pi(Z_i)=\widehat {PS_i}$ (propensity score from IPW), and $\mu(Z_i, A_i)=E[Y|A=1,Z]$ (this is the part of outcome regression model in DRE model). The term in red is said to *augment* the IPW estimator.

## DRE Performance:

---

### When IPW and REG both correct

```{r, echo = FALSE}
mean_dre_estimator <- 
  mean(nested_df$dre)

nested_df %>% 
  ggplot(aes(x = simu_id, y = dre)) +
  ggtitle(paste('The mean of the DRE estimate (both correct) is ', round(mean_dre_estimator, 2))) + 
  geom_point(color = 'red') +
  geom_hline(yintercept = 10) +ylab("ACE estimate")+
  theme_bw()
```

This is fine - we have a very unbiased estimation.

---

### When IPW is Incorrect, REG is correct

Let's explore what happens to DRE when something goes wrong!

```{r}
prop_score_model <- function(data) {
  # OOPS! I forgot var_2
  glm(treatment ~ var_1, data = data, family = 'binomial')
}
```

```{r, echo = FALSE}
# DRE: IPW incorrect
nested_pe_df <- 
  purrr::map2_dfr(1:n_simu, rep(n_obs, n_simu), simu_observational_data) %>% 
  group_by(simu_id) %>% 
  nest() %>% 
  mutate(
    prop_model_w     = map(data, prop_score_model_w),
    mean_model     = map(data, mean_outcome_model),
    model_estimate = map(data, outcome_model_estimator),
    ipw_estimate_w   = map2(data, prop_model_w, ipw_estimator_w),
    dr_estimate    = pmap(list(data, prop_model_w, mean_model), dr_estimator)
  ) %>% 
  ungroup() %>% 
  unnest(c(model_estimate, ipw_estimate_w, dr_estimate))
```


```{r, echo = FALSE}
mean_dre_estimator <- 
  mean(nested_pe_df$dre)

nested_pe_df %>% 
  ggplot(aes(x = simu_id, y = dre)) +
  geom_point(color = 'red') +
  ggtitle(paste('The mean of the DRE estimate (IPW misspecified) is ', round(mean_dre_estimator, 2))) + 
  geom_hline(yintercept = 10) +ylab("ACE estimate")+
  theme_bw()
```

The mean of estimates are above 10, indicating an overestimate of ACE. But this is still acceptable considering IPW is wrongly assigned - this is not too bad.

---

### When REG is incorrect, IPW is correct


```{r,eval=F}
mean_outcome_model_w <- function(data) {
  # HOW COULD I FORGOTTEN var_2??!?! I AM SO DUMB!
  glm(outcome ~ var_1 + treatment, data = data)
}
```


```{r, echo = FALSE}
# REG incorrect, IPW correct
nested_om_df <- 
  purrr::map2_dfr(1:n_simu, rep(n_obs, n_simu), simu_observational_data) %>% 
  group_by(simu_id) %>% 
  nest() %>% 
  mutate(
    prop_model     = map(data, prop_score_model),
    mean_model_w     = map(data, mean_outcome_model_w),
    model_estimate_w = map(data, outcome_model_estimator_w),
    ipw_estimate   = map2(data, prop_model, ipw_estimator),
    dr_estimate    = pmap(list(data, prop_model, mean_model_w), dr_estimator)
  ) %>% 
  ungroup() %>% 
  unnest(c(model_estimate_w, ipw_estimate,dr_estimate))
```

```{r, echo = FALSE}
mean_dre_estimator <- 
  mean(nested_om_df$dre)

nested_om_df %>% 
  ggplot(aes(x = simu_id, y = dre)) +
  geom_point(color = 'red') +
  ggtitle(paste('The mean of the DRE estimate (REG misspecified) is ', round(mean_dre_estimator, 2))) + 
  geom_hline(yintercept = 10) +ylab("ACE estimate")+
  theme_bw()
```


Although it performed worse than the first scenario in DRE (when both REG and IPW are correctly specified), the mean of this estimation is still fair and we can say it maintains robustness.

### When both REG and IPW are incorrect - DRE fails!!

Let’s look at what happens to DRE estimation when both models are incorrectly identified. From previous slides, we learned how robust DRE is - its unbiasedness holds even if one of the models is incorrect, but this is not the case here!

```{r}
prop_score_model_w<- function(data) {
  # OOPS! I forgot var_2
  glm(treatment ~ var_1, data = data, family = 'binomial')
}
mean_outcome_model_w <- function(data) {
  # HOW COULD I FORGOTTEN var_2??!?! I AM SO DUMB!
  glm(outcome ~ var_1 + treatment, data = data)
}
```


```{r}
dr_estimator_w <- function(data, prop_model_w, mean_model_w) {
  data %>% 
    mutate(
      prob = predict(prop_model_w, newdata = data, type = 'response'),
      pred = predict(mean_model_w, newdata = data, type = 'response'),
      augm = (treatment - prob)*pred
    ) %>% 
    summarise(
      EY0_dr = mean((outcome*(1 - treatment) - augm) / (1 - prob)),
      EY1_dr = mean((outcome*treatment - augm) / prob)
    ) %>% 
    mutate(dre_w = EY1_dr - EY0_dr)
}
```

```{r, echo = FALSE}
# Both wrong
nested_bw_df <- 
  purrr::map2_dfr(1:n_simu, rep(n_obs, n_simu), simu_observational_data) %>% 
  group_by(simu_id) %>% 
  nest() %>% 
  mutate(
    prop_model_w     = map(data, prop_score_model_w),
    mean_model_w   = map(data, mean_outcome_model_w),
    model_estimate_w = map(data, outcome_model_estimator_w),
    ipw_estimate_w   = map2(data, prop_model_w, ipw_estimator_w),
    dr_estimate_w    = pmap(list(data, prop_model_w, mean_model_w), dr_estimator_w)
  ) %>% 
  ungroup() %>% 
  unnest(c(model_estimate_w, ipw_estimate_w, dr_estimate_w))
```

```{r, echo = FALSE}
mean_dre_estimator <- 
  mean(nested_bw_df$dre_w)

nested_bw_df %>% 
  ggplot(aes(x = simu_id, y = dre_w)) +
  geom_point(color = 'red') +
  ggtitle(paste('The mean of the DRE estimate (both incorrect) is ', round(mean_dre_estimator, 2))) + 
  geom_hline(yintercept = 10) +ylab("ACE estimate")+
  theme_bw()
```


```{r}
e <- ggplot(nested_pe_df, aes(x=simu_id, y=dre, group=1)) +
  geom_boxplot()+
  geom_hline(yintercept = 10, color='red')+
  ylim(7,14)+
  theme_bw()
f <- ggplot(nested_om_df, aes(x=simu_id, y=dre, group=1))+
  geom_boxplot()+
  geom_hline(yintercept = 10, color='red')+
  ylim(7,14)+
  theme_bw()
g <- ggplot(nested_bw_df, aes(x=simu_id, y=dre_w, group=1))+
  geom_boxplot()+
  geom_hline(yintercept = 10, color='red')+
  ylim(7,14)+
  theme_bw()
plot_grid(e, f, g, labels=c("Incorrect IPW", "Incorrect REG", "Both Incorrect"), ncol = 3, nrow = 1)
```


This boxplot shows the summary of three DRE estimation in the three scenario we simulated. When both are incorrect, the mean of this estimation is far away from 10 (the true ACE, indicated by the red line).

---

# Conclusion

This simulation activity shows how effective DRE is - that its effectiveness depends on correct model specification or outcome regression model (REG), or inverse Probability weighting by propensity score (IPW). Its robustness is maintained when one of the models is incorrect.
	
From previous work, we have also identified and learned why DRE is unbiased when either of them is incorrect. If we have non-randomized trial experiments, we can surely apply methods introduced here today!

---

# References

- Lunceford, Jared K., and Marie Davidian. "Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study." Statistics in medicine 23.19 (2004): 2937-2960.
- YouTube. (2020). Dr. Sebastian Teran Hidalgo - Doubly Robust Estimation of Causal Effects in R. YouTube. Retrieved April 24, 2023, from https://www.youtube.com/watch?v=5rSTEzp_n48.
