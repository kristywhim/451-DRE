{
  "articles": [
    {
      "path": "about.html",
      "title": "Introduction and Motivation",
      "author": [],
      "contents": "\nIntroduction\n“Correlation does not imply causation.” You might have heard this saying from your intro statistics course, and we knew if we’d like to find some evidence that makes us believe the causation. In causal inference, we will investigate the causal relationship between treatment (policy/ dosage/ drug/ habits, etc.) and the outcome of interest. By assigning people to different groups, we try to use various methods to reach the causal conclusion on which group has a better outcome? To do this, we should estimate the “causal effect”.\nA common way of estimating this is to calculate the average causal effect (ACE), denoted by:\n\\(E[Y^{a=1}]- E[Y^{a=0}]\\).\nIn this formula, a represents the potential treatment assignment: \\(a=0\\) means the individual will not be assigned treatment (control), and \\(a=1\\) dictates receiving treatment. In causal inference study, a huge blind spot is that after we observe the data, we want to know what would happen to an individual if they were to be assigned into the other group; unfortunately, this can never happen. As a result, we use capital \\(A\\) to represent the actual treatment received, and \\(a\\) for potential treatment under causal inference studies. \\(Y\\) is the outcome - it can be either quantitative or indicative. Combining together, the formula above makes sense: it records the average difference in the potential outcome between treatment and control group.\nIn statistics, after defining some particular interests and writing them out as mathematical formulas, researchers look for estimators to estimate the true parameter (in our case, that is the ACE). Doubly Robust Estimator (DRE) is a nice one due to its unbiasedness, meaning its average is equivalent to the true value of parameter (ACE). The reason it is called “doubly” is from the fact that DRE is composed of two different estimators: Inverse Probability Weighting (IPW), and Outcome Regression Model (REG). While this may not make any sense, don’t worry - in the next section, “Regression and IPW”, we will firstly go through these two regular, popular approaches in estimating ACE, and see how our doubly robust estimator serves to combine them and become even more powerful!\nMotivation of the project\nEstimating causal effects from data is a fundamental problem in many fields, including health care, economics, and many (social) sciences subjects. Xiang comes from an economic background whereas Kristy comes from a biology background. We teamed up and decided to explore this new, popular method, Doubly Robust estimation (DRE), which is widely used in biostatistics and econometric applications in many Difference-in-Difference (DiD, another way to say we are examining causal effects) experiments and causal inference contexts.\n\n\n\n",
      "last_modified": "2023-04-13T17:26:13-05:00"
    },
    {
      "path": "dre.html",
      "title": "Doubly Robust Estimator",
      "author": [],
      "contents": "\nDRE is a combined method from REG and IPW\nProperties of DRE\nProof of DRE’s unbiasedness\nWhen IPW is misspecified, but REG is correct\nThe first situation is that when we have IPW model\nmisspecified:\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}\\right) \\neq E\\left[Y^{a=1}\\right]\\\\\n\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right) \\neq E\\left[Y^{a=0}\\right]\n\\]\nBut our REG model is correct:\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n} \\hat{Y}_{i}^{a}=E\\left[Y^{a}\\right]\n\\]\nThen the true ACE will become:\n\\[\n\\scriptsize{\\begin{aligned}\nE\\left[\\widehat{\\left[D R E_{a=1}\\right.}-\\widehat{\\left. D R E_{a=0}\\right]}\\right] &= E\\left[\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\hat{Y}_{i}^{a=1}\\right)}{\\widehat{P S_{i}}}+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat{Y}_{i}^{a=0}\\right)}{1-{\\widehat PS_{i}}}+\\hat{Y}_{i}^{a=0}\\right)\\right] \\\\\n& =\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\hat Y_{i}^{a=1}\\right)}{\\widehat{PS_{i}}}+\\hat Y_{i}^{a=1}\\right)\\right]-\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat Y_{i}^{a=0}\\right)}{1-{\\widehat {PS}_{i}}}+\\hat{Y}^{a=0}\\right)\\right] \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{A_{i}\\left(Y_{i}-\\hat Y_{i}^{a=1}\\right)}{\\widehat {PS_{i}}}\\right]+E\\left[\\hat Y_{i}^{a=1}\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat Y_{i}^{a=0}\\right)}{1-{\\widehat P S_{i}}}\\right]+E\\left[\\hat Y_{i}^{a=0}\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat {PS_{i}}}\\right) E\\left[\\left [Y_{i}|A_{i}=1\\right)-E\\left[\\hat Y_{i}^{a=1}|A=1\\right]+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-{\\widehat {PS_{i}}}}\\right) E\\left[Y_i|A_{i}=0]-E[\\hat Y_{i}^{a=0}|A=0\\right]+\\hat{Y}_{i}^{a=0}\\right)\\right. \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{PS}_{i}}\\right)\\left(\\hat{Y}_{i}^{a=1}-\\hat{Y}_{i}^{a=1}\\right)+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{PS}_{i}}\\right)\\left(\\hat{Y}_{i}^{a=0}-\\hat{Y}_{i}^{a=0}\\right)+\\hat{Y}_{i}^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{PS}_{i}}\\right)\\left(0\\right)+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{PS}_{i}}\\right)\\left(0\\right)+\\hat{Y}_{i}^{a=0}\\right) \\\\\n& =\\frac{\\sum_{i=1}^{n} \\hat{Y}_{i}^{a=1}}{n}-\\frac{\\sum_{i=1}^{n} \\hat{Y}_{i}^{a=0}}{n} \\\\\n& =E\\left[Y^{\\alpha=1}\\right]-E\\left[Y^{\\alpha=0}\\right]\n\\end{aligned}}\n\\]\nWhen REG is misspecified, but IPW is correct\nThe second situation is that when we have REG\nmodel misspecified: \\[\n\\frac{1}{n} \\sum_{i=1}^{n} \\hat{Y}_{i}^{a} \\neq E\\left[Y^{a}\\right]\n\\] But our IPW model is correct: \\[\n\\begin{aligned}\n& \\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S_i}}\\right)=E\\left[Y^{a=1}\\right] \\\\\n& \\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right)=E\\left[Y^{a=0}\\right] \\\\\n\\end{aligned}\n\\] First, let’s rearrange DRE’s formula a bit:\n\\[\n\\scriptsize{\n\\begin{aligned}\n\\widehat{D R E}_{a=1}-\\widehat{D R E}_{a=0}&=\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i\\left(Y_i-\\hat{Y}_i^{a=1}\\right)}{\\widehat{P S}_i}+\\hat{Y}_i^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right)\\left(Y_i-\\hat{Y}_i^{a=0}\\right)}{1-\\widehat{P S}_i}+\\hat{Y}_i^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\frac{A_i \\hat{Y}_i^{a=1}}{\\widehat{P S}_i}+\\hat{Y}_i^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\left(\\frac{\\left(1-A_i\\right) \\hat{Y}_i^{a=0}}{1-\\widehat{P S}_i}\\right)+\\hat{Y}_i^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S_i}}-\\left(\\frac{A_i \\widehat{Y}_i^{a=1}}{\\widehat{P S_i}}-\\widehat{Y}_i^{a=1}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S_i}}-\\left(\\frac{\\left(1-A_i\\right) \\hat{Y}_i^{a=0}}{1-\\widehat{P S_i}}-\\widehat{Y}_i^{a=0}\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\hat{Y}_i^{a=1}\\left(\\frac{A_i}{\\widehat{P S}_i}-1\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\hat{Y}_i^{a=0}\\left(\\frac{\\left(1-A_i\\right)}{1-\\widehat{P S_i}}-1\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\hat{Y}_i^{a=1}\\left(\\frac{A_i-\\widehat{P S}_i}{\\widehat{P S}_i}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\hat{Y}_i^{a=0}\\left(\\frac{\\left(1-A_i\\right)-\\left(1-\\widehat{P S}_i\\right)}{1-\\widehat{P S}_i}\\right)\\right) \\\\\n&\n\\end{aligned}}\n\\]\nThen the true ACE becomes: \\[\n\\scriptsize{\\begin{aligned}\nE\\left[\\widehat{D R E_{a=1}}-\\widehat{D R E_{a=0}}\\right]&=E\\left[\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i} Y_{i}}{\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S}_{i}}{\\widehat{P S}_{i}}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S} _{i}}\\right)\\right)\\right] \\\\\n& =\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{A_{i} Y_{i}}{\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S_{i}}}{\\widehat{P S_{i}}}\\right)\\right)\\right]-\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S}_{i}}-\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S_{i}}}\\right)\\right)\\right] \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{A_{i} Y_{i}}{\\widehat{P S}_{i}}\\right]-E\\left[\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S}_{i}}{\\widehat{P S} _{i}}\\right)\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S} _{i}}\\right]-E\\left[\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S_{i}}}\\right)\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right) E\\left[Y_{i}|A=1\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S_{i}}}\\right) E\\left[A_{i}-\\widehat{P S}_{i}\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S_{i}}}\\right) E\\left[Y_{i}|A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S_{i}}}\\right) E\\left[\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right)  E\\left[Y_{i}|A=1\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)\\left(E\\left[A_{i}\\right]-\\widehat{P S_{i}}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S}_{i}}\\right)  E\\left[Y_{i}|A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)\\left(E\\left[\\left(1-A_{i}\\right)\\right]-\\left(1-\\widehat{P S_{i}}\\right)\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right) E\\left[Y_{i} \\mid A=1\\right]-\\left(\\frac{\\widehat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)\\left(\\widehat{P S}_{i}-\\widehat{P S}_{i}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S}_{i}}\\right) E\\left[Y_{i} \\mid A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)\\left(\\left(1-\\widehat{P S}_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)(0)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)(0)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right) \\\\\n& =E\\left[Y^{a=1}\\right]-E\\left[Y^{a=0}\\right]\n\\end{aligned}}\n\\]\nIn either case, we prove that DRE’s unbiasedness\nin estimating the true average causal effects\nholds even though either of IPW/REG has been\nwrongly specified (but the other has to be\ncorrectly modeled). But it fails to work if both\ninverse-probability weighting model (IPW) and\noutcome regression model (REG) are incorrect.\n\n\n\n",
      "last_modified": "2023-04-13T17:26:13-05:00"
    },
    {
      "path": "index.html",
      "title": "Causal Inference: Doubly Robust Estimator",
      "description": "Welcome to the website. This website introduces Doubly Robust Estimator (DRE) in causal inference. This is a class project from course STAT 451: Causal Inference at Macalester College. The contents in this blog are collaborative efforts from Kristy Ma and Xiang Li.\n",
      "author": [],
      "contents": "\nTable of contents\nTo start exploring, please simply navigate to tabs on the upper right corner. We will start by introducing causal inference and motivation behind this project, then diving into mathematical aspect of Doubly Robust Estimator (DRE), and ending up with a simply computation simulation study. Have fun!\nIf you have any questions, please reach out to yma1@macalester.edu and xli2@macalester.edu. Thank you!\n\n\n\n",
      "last_modified": "2023-04-13T17:26:14-05:00"
    },
    {
      "path": "reg-ipw.html",
      "title": "Outcome Regression and Inverse Probability Weighting",
      "author": [],
      "contents": "\nPre DRE: Two common adjusting methods\nOutcome regression (REG)\nInverse Probability Weighting (IPW)\n\n\n\n",
      "last_modified": "2023-04-13T17:26:14-05:00"
    },
    {
      "path": "sim.html",
      "title": "Doubly Robust Estimation of Causal Effects in R",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\nComputational Simulation\nWhat is Causal Inference in Data Science?\nA/B tests are great at allowing us to reach causal claims\nWill A or B cause a better outcome? (i.e, will A cause a bigger client retention than B)\nSometimes we have data on A and B but not generated through a random experiment\nRelying solely on this data won’t allow you to make correct causal claims about A and B\nWe can use causal inference methods to try to estimate the causal effect of using A versus B even from a non random experiment\nWhat is this talk about?\nGoal: estimate a causal effect when you do not have data from a randomized experiment\nStrategy 1: Re-weighting each observation by the probability of receiving A or B so that the data approximates a randomized experiment\nStrategy 2: Modelling the outcome directly with a linear regression\nCombining Idea 1 and 2: To form doubly robust estimator\nWhat is a causal effect?\nConterfactual difference: On average receiving treatment \\(A\\) compared to \\(B\\) will cause a difference in the outcome of \\(\\delta\\)\n\\[\\delta = E[Y(A)] - E[Y(B)]\\]\nwhere \\(Y(A)\\) is the outcome if treatment \\(A\\) had been received, and \\(Y(B)\\) is the outcome if treatment \\(B\\) had been received.\nMean difference: The average difference in outcomes between those receiving \\(A\\) and \\(B\\)\n\\[E[Y|A] - E[Y|B]\\]\nIn an A/B test we can estimate the causal effect \\(\\delta\\) by a simple difference of means because of randomization\n\\[E[Y|A] - E[Y|B] = E[Y(A)] - E[Y(B)]\\]\nIn non randomized data this is not necessarily true\n\\[E[Y|A] - E[Y|B] \\neq E[Y(A)] - E[Y(B)]\\]\nA non randomized data simulation\n–\n\n\nsimu_observational_data <- function(n_obs) {\n  X_1    <- rnorm(n_obs)\n  X_2    <- rnorm(n_obs)\n  XB     <- 0.25*X_1 + 0.25*X_2\n  prob_A <- exp(XB) / (1 + exp(XB)) # This is not an A/B test!\n  A      <- rbinom(n_obs, 1, prob_A) # This is not an A/B test!\n  \n  # The causal effect of receiving A is 10\n  Y      <- 100 + X_1 + X_2 + 10*A + rnorm(n_obs)  \n  \n  data.frame(var_1 = X_1, var_2 = X_2, treatment = A, outcome = Y)  \n} \n\n\nIn this case \\(\\delta = E[Y(A)] - E[Y(B)] = 10\\)\nUnlike a random experiment, the probability of receiving treatment A depends on X_1 and X_2\nThis makes it difficult to to estimate the causal effect\nStrategy 1: Inverse Probability Weighting\nIntuition Behind it\n–\nIn an experiment the probability of receiving a treatment are always equal across all units (i.e., 50%)\nIn the current case, the probability of receiving the treatment depends on variables that affect the outcome\nIf we knew what this probabilities are we could re-weight our sample such that the data would better match a randomized experiment\nIn the re-weighting scheme, units that were very likely to receive the treatment are weighted down and units that were very unlikely to receive the treatment are weighted up\nStrategy 1: Inverse Probability Weighting - Propensity Score\nHow do we estimate these probabilities?\nThe propensity score is just a logistic regression of the probability of receiving the treatment\n\n\nprop_score_model <- function(data) {\n  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')\n}\n\n\nIt is just a fancy name for logistic regression to sound smart at conferences!\nStrategy 1: IPW Estimator\nSimilar to a difference of means but weights each observation inversely proportional to its probability of receiving a treatment\n\\[\\widehat {PS}_i=\\pi(X_{i})\\]\n\\[\\hat{\\delta}_{IPW} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{Y_{i}A_{i}}{\\color{red}{\\pi(X_{i})}} - \\frac{Y_{i}(1-A_{i})}{\\color{red}{1-\\pi(X_{i})}}\\bigg]\\]\n\n\nipw_estimator <- function(data, model) {\n  data %>% \n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>% \n    summarise(\n      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EYA_ipw = mean(outcome*treatment / prob)\n    ) %>% \n    mutate(ipw = EYA_ipw - EYB_ipw)\n}\n\n\nclass: center\n# IPW Performance\n\n\n\nIPW could fail\nIf the model for A is incorrect, it would cause bias in the IPW, which cause IPW to fail.\n\n\nprop_score_model_1 <- function(data) {\n  # OOPS! I forgot var_2\n  glm(treatment ~ var_1, data = data, family = 'binomial')\n}\n\n\n\n\nipw_estimator_1 <- function(data, model) {\n  data %>% \n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>% \n    summarise(\n      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EYA_ipw = mean(outcome*treatment / prob)\n    ) %>% \n    mutate(ipw = EYA_ipw - EYB_ipw)\n}\n\n\n\n\n\nStrategy 2: Model the Outcome\nDefault strategy of data scientist would be to create a linear model\n\\[Y =\\alpha_0 + \\alpha_1 X_1 + \\alpha_2 X_2 +\\delta A+ \\varepsilon\\]\nUse \\(\\hat{\\delta}\\) as the estimator of the causal effect\n\n\nmean_outcome_model <- function(data) {\n  glm(outcome ~ var_1 + var_2 + treatment, data = data)\n}\n\n\n\n\noutcome_model_estimator <- function(data) {\n   mean_model <- mean_outcome_model(data)\n   summary(mean_model)$coefficients['treatment', ][1]\n}\n\n\nclass: center\n# Strategy 2: Performance - Simulation\n\n\n\nOutcome model could also fail\nIf the model for Y is incorrect, it would cause bias in the outcome model, which cause the mdoel to fail.\n\n\nmean_outcome_model_1 <- function(data) {\n  # MISSING var_2??!?!\n  glm(outcome ~ var_1 + treatment, data = data)\n}\n\n\n\n\noutcome_model_estimator_1 <- function(data) {\n   mean_model <- mean_outcome_model_1(data)\n   summary(mean_model)$coefficients['treatment', ][1]\n}\n\n\n\n\nmean_model_estimator_1 <- \n  mean(nested_df$model_estimate)\n\nnested_df %>% \n  ggplot(aes(x = simu_id, y = model_estimate)) +\n  ggtitle(paste('The mean of the model estimate is ', round(mean_model_estimator_1, 2))) + \n  geom_point(color = 'blue') +\n  geom_hline(yintercept = 10) +\n  theme_bw()\n\n\n\nCombining Strategy 1 and 2\n–\nIf the propensity score model is incorrect, strategy 1 will not work\n–\nIf the outcome model is incorrect, strategy 2 will not work\n–\nIf you combine both approaches, you just need either one to work but not both\n–\nAs a data scientist you have 1 out of 2 chances to get the correct answer\n–\nThis is called the doubly robustness property\nThis could also fail but is less likely to do so\nCombining Strategy 1 and 2 - Doubly Robust Estimator\n\\[\\hat{\\delta}_{DR} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{Y_{i}A_{i} -\\color{red}{(A_i-\\pi(X_{i}))\\mu(X_i, A_i)}}{\\pi(X_{i})} - \\frac{Y_{i}(1-A_{i}) -\\color{red}{(A_i-\\pi(X_{i}))\\mu(X_i, A_i)}}{1-\\pi(X_{i})}\\bigg]\\]\nwhere \\[\\mu(X, A) = \\hat{\\alpha}_0 + \\hat{\\alpha}_1 X_1 + \\hat{\\alpha}_2 X_2 +\\hat{\\delta} A\\]\nThe term in red is said to augment the IPW estimator\nIt can be shown that this estimator will consistently estimate \\(\\delta = E[Y(A)]-E[Y(B)]\\) as long as either \\(\\pi(X_{i})\\) or \\(\\mu(X, A)\\) are correct\nCombining Strategy 1 and 2 - Doubly Robust Estimator\n\n\ndr_estimator <- function(data, prop_model, mean_model) {\n  data %>% \n    mutate(\n      prob = predict(prop_model, newdata = data, type = 'response'),\n      pred = predict(mean_model, newdata = data, type = 'response'),\n      augm = (treatment - prob)*pred\n    ) %>% \n    summarise(\n      EYB_dr = mean((outcome*(1 - treatment) - augm) / (1 - prob)),\n      EYA_dr = mean((outcome*treatment - augm) / prob)\n    ) %>% \n    mutate(dre = EYA_dr - EYB_dr)\n}\n\n\nclass: center\n# DRE Performance\n\n\n\nDoubly Robust Estimator - Propensity Score is Incorrect\n\n\nprop_score_model <- function(data) {\n  # OOPS! I forgot var_2\n  glm(treatment ~ var_1, data = data, family = 'binomial')\n}\n\n\nclass: center\n# Doubly Robust Estimator - Propensity Score is Incorrect\n\n\n\n\n\n\n# Doubly Robust Estimator - Mean Model is Incorrect\n\n# Doubly Robust Estimator - Mean Model is Incorrect\n\n\n\n\nConclusion\nIf you have non randomized data you cannot simply calculate the difference in means between \\(A\\)\nand \\(B\\) to estimate the causal effect\nYou can use the IPW estimator based on a logistic regression of the probability of receiving the treatment\nYou can model the outcome based on a linear regression with the confounding variables as well as \\(A\\)\nOr you can use the doubly robust estimator which will work as long as either the logistic or the linear regression are correct, but not both\nReferences\nLunceford, Jared K., and Marie Davidian. “Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study.” Statistics in medicine 23.19 (2004): 2937-2960.\n\n\n\n",
      "last_modified": "2023-04-13T17:26:22-05:00"
    },
    {
      "path": "wrapup.html",
      "title": "Wrap-up and Conclusion",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\nTitle\n\n\n\n",
      "last_modified": "2023-04-13T17:26:23-05:00"
    }
  ],
  "collections": []
}
