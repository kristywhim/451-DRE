{
  "articles": [
    {
      "path": "about.html",
      "title": "Introduction and Motivation",
      "author": [],
      "contents": "\nIntroduction\n“Correlation does not imply causation.” You might have heard this saying from your intro statistics course, and we knew if we’d like to find some evidence that makes us believe the causation. In causal inference, we will investigate the causal relationship between treatment (policy/ dosage/ drug/ habits, etc.) and the outcome of interest. By assigning people to different groups, we try to use various methods to reach the causal conclusion on which group has a better outcome? To do this, we should estimate the “causal effect”.\nA common way of estimating this is to calculate the average causal effect (ACE), denoted by:\n\\(E[Y^{a=1}]- E[Y^{a=0}]\\).\nIn this formula, a represents the potential treatment assignment: \\(a=0\\) means the individual will not be assigned treatment (control), and \\(a=1\\) dictates receiving treatment. In causal inference study, a huge blind spot is that after we observe the data, we want to know what would happen to an individual if they were to be assigned into the other group; unfortunately, this can never happen. As a result, we use capital \\(A\\) to represent the actual treatment received, and \\(a\\) for potential treatment under causal inference studies. \\(Y\\) is the outcome - it can be either quantitative or indicative. Combining together, the formula above makes sense: it records the average difference in the potential outcome between treatment and control group.\nIn statistics, after defining some particular interests and writing them out as mathematical formulas, researchers look for estimators to estimate the true parameter (in our case, that is the ACE). Doubly Robust Estimator (DRE) is a nice one due to its unbiasedness, meaning its average is equivalent to the true value of parameter (ACE). The reason it is called “doubly” is from the fact that DRE is composed of two different estimators: Inverse Probability Weighting (IPW), and Outcome Regression Model (REG). While this may not make any sense, don’t worry - in the next section, “Regression and IPW”, we will firstly go through these two regular, popular approaches in estimating ACE, and see how our doubly robust estimator serves to combine them and become even more powerful!\nMotivation of the project\nEstimating causal effects from data is a fundamental problem in many fields, including health care, economics, and many (social) sciences subjects. Xiang comes from an economic background whereas Kristy comes from a biology background. We teamed up and decided to explore this new, popular method, Doubly Robust estimation (DRE), which is widely used in biostatistics and econometric applications in many Difference-in-Difference (DiD, another way to say we are examining causal effects) experiments and causal inference contexts.\n\n\n\n",
      "last_modified": "2023-05-01T12:26:42-05:00"
    },
    {
      "path": "dre.html",
      "title": "Doubly Robust Estimator",
      "author": [],
      "contents": "\nDRE is a combined method from REG and IPW\nIn the previous two sections, we used REG and IPW to recover the mean outcome when the population received treatment (A=1) and when the population did not receive the treatment (A=0) and form ACE formulas. We assumed we specified the correct model for both approaches, which allowed us to build an unbiased model. However, the assumption does not always hold, and it is often unrealistic and incapable of defining the model that involves all relevant confounding variables, measured and unmeasured.\nTo address this limitation that both estimators have, it will be nice to combine the outcome regression model with a model for the exposure to estimate the causal effect of an exposure on an outcome, which forms the double robust estimator. It combines these 2 approaches such that only 1 of the 2 models needs to be correctly specified to make unbiasedness holds.\nWe construct a combined estimator such that if we construct one model correctly (REG or IPW), our combined estimator will produce unbiased estimates of the average causal effect. More importantly, we don’t need to know which of the two models is correctly specified (REG or IPW); just that at least one is correctly specified is enough. In simple words, it means that we don’t put all of our eggs in one basket with one approach, rather we reduce our risk of getting a biased model by having two shots at getting the answer correct.\nProperties of DRE\nBecause of its hybrid feature, DRE has better flexibility and robustness to model misspecification, which allows it to be less biased and useful in situations with uncertainty about the adequacy of the adjustment for confounding. Since this method has been applied in various fields to estimate the average causal effects of interventions, policies, and programs that are closely related to our lives. Therefore, understanding the principles of double robustness estimation and applying this method to real-world data is critical for drawing causal inferences from observational data.\nIn the following section, we are going to use this DRE model that contains the binary treatment variable A and the continuous outcome variable Y to prove the unbiasedness in different conditions.\nBelow are equations showing how DRE estimates the average causal effect.\n\\[\n\\begin{gathered}\n\\widehat{D R E}_{a=1}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\widehat{Y}_{i}^{a=1}\\right)}{\\widehat{P S}_{i}}+\\widehat{Y}_{i}^{a=1}\\right) \\\\\n\\widehat{D R E}_{a=0}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\widehat{Y}_{i}^{a=0}\\right)}{1-\\widehat{P S}_{i}}+\\widehat{Y}_{i}^{a=0}\\right) \\\\\n\\widehat{D R E}_{a=1}-\\widehat{D R E}_{a=0}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\widehat{Y}_{i}^{a=1}\\right)}{\\widehat{P S}_{i}}+\\widehat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\widehat{Y}_{i}^{a=0}\\right)}{1-\\widehat{P S}_{i}}+\\widehat{Y}_{i}^{a=0}\\right)\n\\end{gathered}\n\\]\nThe variables in the DRE above are as follows:\n\\(\\boldsymbol{A_{i}}\\) : observed Intervention in the data for observation “\\(i\\)”\n\\(\\boldsymbol{Y_{i}}\\) : observed Outcome in the data for observation ” \\(i\\) ”\n\\(\\boldsymbol{\\widehat{Y}_{i}^{a=1}}\\) : predicted Outcome for observation ” \\(i\\) ” from Standardization via the parametric \\(g\\) formula under Intervention \\(a=1\\)\n\\(\\boldsymbol {\\widehat{Y}_{i}^{a=0}}\\) : predicted Outcome for observation “\\(i\\)” from Standardization via the parametric \\(g\\) formula under Intervention \\(a=0\\)\n\\(\\widehat{\\boldsymbol{PS}}_{\\mathrm{i}}\\) : predicted Propensity Score (i.e. \\(\\operatorname{Pr}\\left[A=1 \\mid C_{1}, C_{2}\\right]\\) ) for observation “\\(i\\)”.\n\\(\\widehat{\\boldsymbol{D R E}}_{a}\\) : Doubly Robust Estimator (DRE) under Intervention \\(a\\)\n\\(\\boldsymbol{n}\\) : total number of observations in the observed dataset\nUnder correct specification of either the Outcome Regression (REG) or Inverse Probability Weighting Model (IPW), the following equalities hold:\n\\[\n\\begin{aligned}\nE\\left[\\widehat{D R E}_{a=1}\\right] & =E\\left[Y^{a=1}\\right] \\\\\nE\\left[\\widehat{D R E}_{a=0}\\right] & =E\\left[Y^{a=0}\\right] \\\\\nE\\left[\\widehat{D R E}_{a=1}-\\widehat{D R E}_{a=0}\\right] & =E\\left[Y^{a=1}\\right]-E\\left[Y^{a=0}\\right]\n\\end{aligned}\n\\]\nProof of DRE’s unbiasedness\nWe have talked about how DRE is robust and unbiased when either REG and IPW model is incorrect. Let’s take it in more depth and see how this works! We will divide this into two scenarios:\n1. when IPW is incorrect\n2. when REG is incorrect.\nWhen IPW is misspecified, but REG is correct\nThe first situation is that when we have IPW model misspecified:\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}\\right) \\neq E\\left[Y^{a=1}\\right]\\\\\n\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right) \\neq E\\left[Y^{a=0}\\right]\n\\]\nBut our REG model is correct:\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n} \\hat{Y}_{i}^{a}=E\\left[Y^{a}\\right]\n\\]\nThen the true ACE will become:\n\\[\n\\scriptsize{\\begin{aligned}\nE\\left[\\widehat{\\left[D R E_{a=1}\\right.}-\\widehat{\\left. D R E_{a=0}\\right]}\\right] &= E\\left[\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\hat{Y}_{i}^{a=1}\\right)}{\\widehat{P S_{i}}}+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat{Y}_{i}^{a=0}\\right)}{1-{\\widehat PS_{i}}}+\\hat{Y}_{i}^{a=0}\\right)\\right] \\\\\n& =\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\hat Y_{i}^{a=1}\\right)}{\\widehat{PS_{i}}}+\\hat Y_{i}^{a=1}\\right)\\right]-\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat Y_{i}^{a=0}\\right)}{1-{\\widehat {PS}_{i}}}+\\hat{Y}^{a=0}\\right)\\right] \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{A_{i}\\left(Y_{i}-\\hat Y_{i}^{a=1}\\right)}{\\widehat {PS_{i}}}\\right]+E\\left[\\hat Y_{i}^{a=1}\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat Y_{i}^{a=0}\\right)}{1-{\\widehat P S_{i}}}\\right]+E\\left[\\hat Y_{i}^{a=0}\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat {PS_{i}}}\\right) E\\left[\\left [Y_{i}|A_{i}=1\\right)-E\\left[\\hat Y_{i}^{a=1}|A=1\\right]+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-{\\widehat {PS_{i}}}}\\right) E\\left[Y_i|A_{i}=0]-E[\\hat Y_{i}^{a=0}|A=0\\right]+\\hat{Y}_{i}^{a=0}\\right)\\right. \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{PS}_{i}}\\right)\\left(\\hat{Y}_{i}^{a=1}-\\hat{Y}_{i}^{a=1}\\right)+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{PS}_{i}}\\right)\\left(\\hat{Y}_{i}^{a=0}-\\hat{Y}_{i}^{a=0}\\right)+\\hat{Y}_{i}^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{PS}_{i}}\\right)\\left(0\\right)+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{PS}_{i}}\\right)\\left(0\\right)+\\hat{Y}_{i}^{a=0}\\right) \\\\\n& =\\frac{\\sum_{i=1}^{n} \\hat{Y}_{i}^{a=1}}{n}-\\frac{\\sum_{i=1}^{n} \\hat{Y}_{i}^{a=0}}{n} \\\\\n& =E\\left[Y^{\\alpha=1}\\right]-E\\left[Y^{\\alpha=0}\\right]\n\\end{aligned}}\n\\]\nWhen REG is misspecified, but IPW is correct\nThe second situation is that when we have REG\nmodel misspecified:\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n} \\hat{Y}_{i}^{a} \\neq E\\left[Y^{a}\\right]\n\\]\nBut our IPW model is correct:\n\\[\n\\begin{aligned}\n& \\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S_i}}\\right)=E\\left[Y^{a=1}\\right] \\\\\n& \\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right)=E\\left[Y^{a=0}\\right] \\\\\n\\end{aligned}\n\\]\nFirst, let’s rearrange DRE’s formula a bit:\n\\[\n\\scriptsize{\n\\begin{aligned}\n\\widehat{D R E}_{a=1}-\\widehat{D R E}_{a=0}&=\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i\\left(Y_i-\\hat{Y}_i^{a=1}\\right)}{\\widehat{P S}_i}+\\hat{Y}_i^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right)\\left(Y_i-\\hat{Y}_i^{a=0}\\right)}{1-\\widehat{P S}_i}+\\hat{Y}_i^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\frac{A_i \\hat{Y}_i^{a=1}}{\\widehat{P S}_i}+\\hat{Y}_i^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\left(\\frac{\\left(1-A_i\\right) \\hat{Y}_i^{a=0}}{1-\\widehat{P S}_i}\\right)+\\hat{Y}_i^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S_i}}-\\left(\\frac{A_i \\widehat{Y}_i^{a=1}}{\\widehat{P S_i}}-\\widehat{Y}_i^{a=1}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S_i}}-\\left(\\frac{\\left(1-A_i\\right) \\hat{Y}_i^{a=0}}{1-\\widehat{P S_i}}-\\widehat{Y}_i^{a=0}\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\hat{Y}_i^{a=1}\\left(\\frac{A_i}{\\widehat{P S}_i}-1\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\hat{Y}_i^{a=0}\\left(\\frac{\\left(1-A_i\\right)}{1-\\widehat{P S_i}}-1\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\hat{Y}_i^{a=1}\\left(\\frac{A_i-\\widehat{P S}_i}{\\widehat{P S}_i}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\hat{Y}_i^{a=0}\\left(\\frac{\\left(1-A_i\\right)-\\left(1-\\widehat{P S}_i\\right)}{1-\\widehat{P S}_i}\\right)\\right) \\\\\n&\n\\end{aligned}}\n\\]\nThen the true ACE becomes:\n\\[\n\\scriptsize{\\begin{aligned}\nE\\left[\\widehat{D R E_{a=1}}-\\widehat{D R E_{a=0}}\\right]&=E\\left[\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i} Y_{i}}{\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S}_{i}}{\\widehat{P S}_{i}}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S} _{i}}\\right)\\right)\\right] \\\\\n& =\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{A_{i} Y_{i}}{\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S_{i}}}{\\widehat{P S_{i}}}\\right)\\right)\\right]-\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S}_{i}}-\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S_{i}}}\\right)\\right)\\right] \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{A_{i} Y_{i}}{\\widehat{P S}_{i}}\\right]-E\\left[\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S}_{i}}{\\widehat{P S} _{i}}\\right)\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S} _{i}}\\right]-E\\left[\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S_{i}}}\\right)\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right) E\\left[Y_{i}|A=1\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S_{i}}}\\right) E\\left[A_{i}-\\widehat{P S}_{i}\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S_{i}}}\\right) E\\left[Y_{i}|A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S_{i}}}\\right) E\\left[\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right)  E\\left[Y_{i}|A=1\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)\\left(E\\left[A_{i}\\right]-\\widehat{P S_{i}}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S}_{i}}\\right)  E\\left[Y_{i}|A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)\\left(E\\left[\\left(1-A_{i}\\right)\\right]-\\left(1-\\widehat{P S_{i}}\\right)\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right) E\\left[Y_{i} \\mid A=1\\right]-\\left(\\frac{\\widehat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)\\left(\\widehat{P S}_{i}-\\widehat{P S}_{i}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S}_{i}}\\right) E\\left[Y_{i} \\mid A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)\\left(\\left(1-\\widehat{P S}_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)(0)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)(0)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right) \\\\\n& =E\\left[Y^{a=1}\\right]-E\\left[Y^{a=0}\\right]\n\\end{aligned}}\n\\]\nIn either case, we prove that DRE’s unbiasedness in estimating the true average causal effects holds even though either of IPW/REG has been wrongly specified (but the other has to be correctly modeled). But it fails to work if both inverse-probability weighting model (IPW) and outcome regression model (REG) are incorrect.\n\n\n\n",
      "last_modified": "2023-05-01T12:26:42-05:00"
    },
    {
      "path": "index.html",
      "title": "Causal Inference: Doubly Robust Estimator",
      "description": "Welcome to the website. This website introduces Doubly Robust Estimator (DRE) in causal inference. This is a class project from course STAT 451: Causal Inference at Macalester College. The contents in this blog are collaborative efforts from Kristy Ma and Xiang Li.\n",
      "author": [],
      "contents": "\nTable of contents\nTo start exploring, please simply navigate to tabs on the upper right corner. We will start by introducing causal inference and motivation behind this project, then diving into mathematical aspect of Doubly Robust Estimator (DRE), and ending up with a simply computation simulation study. Have fun!\nIf you have any questions, please reach out to yma1@macalester.edu and xli2@macalester.edu. Thank you!\n\n\n\n",
      "last_modified": "2023-05-01T12:26:42-05:00"
    },
    {
      "path": "reg-ipw.html",
      "title": "Outcome Regression and Inverse Probability Weighting",
      "author": [],
      "contents": "\nPre DRE: Two common adjusting methods\nPreviously, we talked about two commonly used approaches for estimating ACE: outcome regression estimator (REG) and Inverse-Probability Weighting (IPW). When using outcome regression and IPW to estimate a causal effect, both methods are unbiased only if the statistical model is correctly specified- this requires our knowledge of predictors and guessing their associations with outcome correctly (which can be really difficult and impractical!). Let’s take a look at how they work.\nOutcome regression (REG)\nThe central idea about Outcome Regression Estimator (REG) is to cut off all non-causal paths between treatment variable A to outcome variable Y by applying the idea of Markov Assumption and D-separation in the causal graph (also known as directed acyclic graph, DAG).\nOutcome regression estimator is a statistical method used to estimate the relationship between treatment variables (A) and the outcome variable (Y). The outcome regression estimator can be used to make predictions about the outcome variable based on the values of the treatment variables, and it can also be used to test hypotheses about the relationship between the treatment variables and the outcome variable.\nThrough the Causal Markov Assumption the D-separation, the distributions of A and Y conditional on confounder set Z are conditionally independent. In this way, we successfully block association flow along non-causal paths because we have controlled the study units to share same values of Z before we compare them. This also means we have achieved conditionally exchangeability of the outcomes Y across treatment groups A. Therefore, now we are able to inspect within the subset of the data defined by Z and compare the average outcome (probability of Y) between the treatment groups A.\nThe mathematical formula expressing the REG model is: where we fit a linear regression on A and Z, \\(\\beta_1\\) will then become our estimation on average causal effect (ACE): it represents the change in the expected value of outcome Y when we compare a treatment unit to a control unit, assuming they share the same Z value.\n\\[\nE[Y|A,Z]=\\beta_0+\\beta_1A+\\beta_2Z\\\\\n\\hat \\beta_1=E[Y|A=1,Z]-E[Y|A=0,Z]=E[Y^{a=1}|Z]-E[Y^{a=0}|Z]\n\\]\nBy calculating Yi for each observation in every treatment condition, \\(A=1\\) and \\(A=0\\), we get the sample mean of outcome \\(E[Y^{A=a}]\\):\n\\[\nE[Y^{A=a}]=\\frac{1}{n} \\sum_{i=1}^n \\hat Y_i\n\\]\nWhen Z is both correctly identified and modeled, this is an unbiased estimate of the mean potential outcome had the entire population received treatment for all people (so both treatment and control groups).\nInverse Probability Weighting (IPW)\nThe central idea about IPW is to cut off the relationship between potential confounders Z to treatment variable A by reconstructing “pseudo population” from the data we have.\nInverse probability weighting (IPW) relies on the idea of building a logistic regression model that can be used to estimate the probability of being a treatment/ control unit observed for a particular observation (assuming that the confounders have been controlled). This predicted probability (after being converted from the output of the logistic regression model) is called propensity score in subsequent analyses. IPW is unique in measuring average causal effect by removing confounding variables using these weights.\nThis method is used under non-randomized trials (where the randomized trials are seen as the “gold standard” in causal studies): the number of people receiving treatment and control are not equal. As groups are imbalanced, we want to create a “pseudo-population” where half are treated and half are not treated.\nThis is achieved by re-weighting outcomes so that they reflect the global distribution of population sizes and help us to remove non-causal paths, thus leading to unbiased comparison. The weight for a particular Z group is the inverse of the propensity score, the probability of being assigned to the treatment/ control group, given patients attributes (Z).\n\\[\nWeight_{a=1}=\\frac{1}{P(A=1|Z)}=\\frac{1}{\\widehat {PS_i}}\nWeight_{a=0}=\\frac{1}{P(A=0|Z)}=\\frac{1}{1-\\widehat {PS_i}}\n\\]\nThis intuition can be reflected in the formula, where we adjust the formula by multiplying the propensity score, we end up getting the inverse probability weighting (IPW) formula:\n\\[\nP(Y|A=a)=\\sum_{i=1}^n P(Y|A=a, Z)P(Z)\\\\\nE[Y^{a=1}]=\\frac{1}{n}\\sum_{i=1}^n(\\frac {E[Y_i|A=1]}{\\widehat{PS_i}})\\\\\nE[Y^{a=0}]=\\frac{1}{n}\\sum_{i=1}^n(\\frac {E[Y_i|A=0]}{1-\\widehat{PS_i}})\\\\\nACE=E[Y^{a=1}]-E[Y^{a=0}]\n\\]\n\n\n\n",
      "last_modified": "2023-05-01T12:26:43-05:00"
    },
    {
      "path": "sim.html",
      "title": "Doubly Robust Estimator: simulation activity in R",
      "author": [],
      "contents": "\nComputational Simulation\nGoal: estimate a causal effect when you do not have data from a randomized experiment\nStrategy 1: Re-weighting each observation by the probability of receiving A or B so that the data approximates a randomized experiment\nStrategy 2: Modelling the outcome directly with a linear regression\nCombining Idea 1 and 2: To form doubly robust estimator\nSetting up data\nWe assign \\(X_1\\) and \\(X_2\\) as causal variables, and define a true ACE of 10.\n\n\nsimu_observational_data <- function(simu_id = 1, n_obs) {\n  X_1    <- rnorm(n_obs)\n  X_2    <- rnorm(n_obs)\n  XB     <- 0.2*X_1 + 0.2*X_2\n  prob_A <- exp(XB) / (1 + exp(XB))\n  A      <- rbinom(n_obs, 1, prob_A)\n \n  # We set the true causal effect of treatment A is 10\n  Y      <- 100 + X_1 + 2*X_2 + 10*A + rnorm(n_obs)\n \n  # summarize variables into a data frame\n  data.frame(simu_id = simu_id, n_obs = n_obs,\n             var_1 = X_1, var_2 = X_2,\n             treatment = A, outcome = Y)  \n}\n\n\n\n\nn_simu <- 150\nn_obs <- 200\n\nset.seed(1)\n\ndata <-\n  purrr::map2_dfr(1:n_simu, rep(n_obs, n_simu), simu_observational_data) %>%\n  group_by(simu_id)\n\nsl.lib <- c(\"SL.mean\",\"SL.glm\")\n\n\nIPW model\nWe create the correct model of IPW with both variables, \\(X_1\\) and \\(X_2\\).\n\n\nprop_score_model <- function(data) {\n  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')\n}\n\n\n\n\n#IPW estimator is correct\nipw_estimator <- function(data, model) {\n  data %>%\n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>%\n    summarise(\n      # Calculate expected value for both treatment and non-treatment using IPW equation\n      EY0_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EY1_ipw = mean(outcome*treatment / prob)\n    ) %>%\n    # Calculate ACE\n    mutate(ipw = EY1_ipw - EY0_ipw)\n}\n\n\nWe miss \\(X_2\\) in the model, which makes the model misspecified.\n\n\nprop_score_model_w <- function(data) {\n  # OOPS! I forgot var_2\n  glm(treatment ~ var_1, data = data, family = 'binomial')\n}\n\n\n\n\n# IPW estimator is wrong\nipw_estimator_w <- function(data, model) {\n  data %>%\n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>%\n    summarise(\n      # Calculate expected value for both treatment and non-treatment using IPW equation\n      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EYA_ipw = mean(outcome*treatment / prob)\n    ) %>%\n    # Calculate ACE\n    mutate(ipw_w = EYA_ipw - EYB_ipw)\n}\n\n\nREG model\nWe create the correct model of outcome regression model with both variables, \\(X_1\\) and \\(X_2\\).\n\n\nmean_outcome_model <- function(data) {\n  glm(outcome ~ treatment + var_1 + var_2, data = data)\n}\n\n\n\n\n#REG estimator is correct\noutcome_model_estimator <- function(data) {\n   mean_model <- mean_outcome_model(data) # Compute the model\n   summary(mean_model)$coefficients['treatment', ][1] # Coefficient for treatment\n}\n\n\nWe miss \\(X_2\\) in this model, which makes this REG model misspecified.\n\n\nmean_outcome_model_w <- function(data) {\n  # MISSING var_2??!?!\n  glm(outcome ~ var_1 + treatment, data = data)\n}\n\n\n\n\n# REG estimator is wrong\noutcome_model_estimator_w <- function(data) {\n   mean_model <- mean_outcome_model_w(data) # Compute the model\n   summary(mean_model)$coefficients['treatment', ][1] # Coefficient for treatment\n}\n\n\nData Simulation\nWe build the data with all different model specifications.\n\n\nn_simu <- 150\nn_obs <- 200\n\nset.seed(1)\n\nnested_df <-\n  purrr::map2_dfr(1:n_simu, rep(n_obs, n_simu), simu_observational_data) %>%\n  group_by(simu_id) %>%\n  nest() %>%\n  mutate(\n    # correct ipw model\n    prop_model     = map(data, prop_score_model),\n    # incorrect ipw model\n    prop_model_w   = map(data, prop_score_model_w),\n    # correct reg model\n    mean_model     = map(data, mean_outcome_model),\n    # incorrect reg model\n    mean_model_w   = map(data, mean_outcome_model_w),\n    # correct reg estimation\n    model_estimate = map(data, outcome_model_estimator),\n    # incorrect reg estimation\n    model_estimate_w = map(data, outcome_model_estimator_w),\n    # correct ipw estimation\n    ipw_estimate   = map2(data, prop_model, ipw_estimator),\n    # incorrect ipw estimation\n    ipw_estimate_w = map2(data, prop_model_w, ipw_estimator_w),\n  ) %>%\n  ungroup() %>%\n  unnest(c(model_estimate, model_estimate_w, ipw_estimate, ipw_estimate_w))\n\n\nNow, we have five models: IPW (both correct and incorrect), REG (both correct and incorrect), and DRE.\nStrategy 1: Inverse Probability Weighting (IPW)\nIntuition Behind it\nIn an experiment the probability of receiving a treatment are always equal across all units (50%)\nIn the current case, the probability of receiving the treatment depends on variables that affect the outcome\nIf we knew what this probabilities are we could re-weight our sample such that the data would better match a randomized experiment - by creating the “pesudopopulation” (mentioned earlier)\nReminder: propensity score is just a logistic regression of the probability of receiving the treatment, giving their \\(Z\\) values (confounders)\nIn our example, we proposed the correct IPW model:\n\n\nprop_score_model <- function(data) {\n  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')\n}\n\n\nIntroducing IPW estimator\nSimilar to a difference of means but weights each observation inversely proportional to its probability of receiving a treatment (propensity score \\(\\widehat {PS_i}\\))\n\\[\\hat{\\delta}_{IPW} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{E[Y_{i}|{A=1}]}{\\color{red}{\\widehat {PS_i}}} - \\frac{E[Y_{i}|{A=0}]}{\\color{red}{1-\\widehat {PS_i}}}\\bigg]\\]\nGenerating IPW estimator and calculate ACE by IPW equation:\n\n\nipw_estimator <- function(data, model) {\n  data %>%\n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>%\n    summarise(\n      EY0_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EY1_ipw = mean(outcome*treatment / prob)\n    ) %>%\n    mutate(ipw = EY1_ipw - EY0_ipw)\n}\n\n\nIPW Performance\nPlot for correct IPW\n\n\n\nThe plot shows the data points are evenly spread around 10, and the mean of correct IPW estimate is 10, which is very close to the true ACE we set.\nIPW could fail\nIf the model for A is incorrect, it would cause bias in the IPW, which cause IPW to fail. We used the biased ipw results from the ‘nested_df’ dataset.\n\n\n\nThe plot shows a obvious trend that all data points from biased IPW model shift upward, which the ACE for incorrect IPW model is higher than the ACE=10 we set in the beginning.\n\n\n\nWe overestimated the true ACE (which is 10) if we wrongly specified the model form in IPW setting.\nStrategy 2: REG estimator (model the outcome)\n\n\noutcome_model_estimator <- function(data) {\n   mean_model <- mean_outcome_model(data)\n   summary(mean_model)$coefficients['treatment', ][1]\n}\n\n\nREG Performance\n\n\n\nWhen outcome model is correctly modelled, this shows unbiased estimation of ACE.\nREG could also fail\nIf the model for Y is incorrect (as we recalled we left var_2 out), it will cause bias in the REG outcome model, which cause the model to fail.\n\n\n\n\n\n\nWe also overestimated the true ACE (10) if our REG model is mis-specified.\nCombining Strategy 1 and 2\nIf the propensity score model is incorrect, strategy 1 will not work\nIf the outcome model is incorrect, strategy 2 will not work\nIf you combine both approaches, you just need either one to work but not both\nThis is “doubly robust” property!\nDoubly Robust Estimator\nDRE’s estimation of average causal effect can be summarized into this equation (it is the same thing as the one in the previous section but we changed some notations):\n\\[\\hat{\\delta}_{DRE} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{Y_{i}A_{i} -\\color{red}{(A_i-\\pi(Z_{i}))\\mu(Z_i, A_i)}}{\\pi(Z_{i})} - \\frac{Y_{i}(1-A_{i}) -\\color{red}{(A_i-\\pi(Z_{i}))\\mu(Z_i, A_i)}}{1-\\pi(Z_{i})}\\bigg]\\]\nwhere \\(\\pi(Z_i)=\\widehat {PS_i}\\) (propensity score from IPW), and \\(\\mu(Z_i, A_i)=E[Y|A=1,Z]\\) (this is the part of outcome regression model in DRE model). The term in red is said to augment the IPW estimator.\nWhen IPW and REG both correct\n\n\nAIPW_00 <- AIPW$new(Y= data$outcome, \n                    A= data$treatment,\n                    W= subset(data,select=c(var_1,var_2)), # Covariates for both IPW and REG models\n                    Q.SL.library = sl.lib, # Algorithms used for the outcome model (Q).\n                    g.SL.library = sl.lib, # Algorithms used for the exposure model (g).\n                    k_split = 10, # Number of folds for splitting\n                    verbose=FALSE)\nAIPW_00$fit()\n# Estimate the average causal effects\nAIPW_00$summary(g.bound = 0.25)\ndre_00 <- AIPW_00$estimates$risk_A1[1] - AIPW_00$estimates$risk_A0[1] # Calculate ACE\ndre_00\n\nEstimate \n10.00317 \n\nThis is fine - we have a very unbiased estimation.\nLet’s analyze DRE’s performance under following settings:\nWhen IPW is Incorrect, REG is correct\nLet’s explore what happens to DRE when something goes wrong!\n\n\nAIPW_01 <- AIPW$new(Y= data$outcome,\n                    A= data$treatment,\n                    W.Q= subset(data,select=c(var_1,var_2)), # Covariates for the REG model.\n                    W.g= subset(data,select=var_1), # Covariates for the IPW model.\n                    Q.SL.library = sl.lib,\n                    g.SL.library = sl.lib,\n                    k_split = 10,\n                    verbose=FALSE)\nAIPW_01$fit()\nAIPW_01$summary(g.bound = 0.25)\ndre_01 <- AIPW_01$estimates$risk_A1[1] - AIPW_01$estimates$risk_A0[1]\ndre_01\n\nEstimate \n 10.0033 \n\nThe mean of estimates are around 10. This indicates that this estimator is unbiased when IPW is misspecified.\nWhen REG is incorrect, IPW is correct\n\n\nAIPW_10 <- AIPW$new(Y= data$outcome,\n                    A= data$treatment,\n                    W.Q= subset(data,select=var_1), \n                    W.g= subset(data,select=c(var_1,var_2)),\n                    Q.SL.library = sl.lib,\n                    g.SL.library = sl.lib,\n                    k_split = 10,\n                    verbose=FALSE)\nAIPW_10$fit()\nAIPW_10$summary(g.bound = 0.25)\ndre_10 <- AIPW_10$estimates$risk_A1[1] - AIPW_10$estimates$risk_A0[1]\ndre_10\n\nEstimate \n10.00384 \n\nThe mean of estimates are also around 10. This indicates that this estimator is unbiased when REG is wrongly modeled.\nWhen both REG and IPW are incorrect - DRE fails!!\nLet’s look at what happens to DRE estimation when both models are incorrectly identified. From previous slides, we learned how robust DRE is - its unbiasedness holds even if one of the models is incorrect, but this is not the case here!\n\n\nAIPW_11 <- AIPW$new(Y= data$outcome,\n                    A= data$treatment,\n                    W.Q= subset(data,select=var_1), \n                    W.g= subset(data,select=var_1),\n                    Q.SL.library = sl.lib,\n                    g.SL.library = sl.lib,\n                    k_split = 10,\n                    verbose=FALSE)\nAIPW_11$fit()\nAIPW_11$summary(g.bound = 0.25)\ndre_11 <- AIPW_11$estimates$risk_A1[1] - AIPW_11$estimates$risk_A0[1]\ndre_11\n\nEstimate \n 10.4585 \n\nThe mean of estimates are above 10 (10.46). This indicates that this estimator is biased when both REG and IPW are wrongly modeled.\nLooking at them together!\n\n               ACE estimates\nBoth Correct        10.00317\nIPW Incorrect       10.00330\nREG Incorrect       10.00384\nBoth Incorrect      10.45850\n\nConclusion\nThis simulation activity shows how effective DRE is - that its effectiveness depends on correct model specification or outcome regression model (REG), or inverse Probability weighting by propensity score (IPW). Its robustness is maintained when one of the models is incorrect.\nFrom previous work, we have also identified and learned why DRE is unbiased when either of them is incorrect. If we have non-randomized trial experiments, we can surely apply methods introduced here today!\n\n\n\n",
      "last_modified": "2023-05-01T12:27:00-05:00"
    },
    {
      "path": "wrapup.html",
      "title": "Wrap-up and Conclusion",
      "author": [],
      "contents": "\nThat summarizes our exploration on doubly robust estimator!\nIf you are interested in more details, this links to a cool paper from Callaway and Sant’Anna (2020) on using methods similar to doubly robust estimator described here to measure dynamic treatment effects in economic DiD experiments (difference-in-difference) studies. The paper discusses the common estimation and interference procedures for measuring treatment effects in varying time periods.\nThank you for reading and having the interest on our project!\nReference:\n\n“Doubly Robust Estimators - Inverse Probability of Treatment Weighting (IPTW).” Coursera, www.coursera.org/lecture/crash-course-in-causality/doubly-robust-estimators-hZjgB. Accessed 28 Apr. 2023.\nHidalgo, Sebastian Jose Teran. “Dr. Sebastian Teran Hidalgo - Doubly Robust Estimation of Causal Effects in R.” Www.youtube.com, 7 Oct. 2020, www.youtube.com/watch?v=5rSTEzp_n48. Accessed 28 Apr. 2023.\nHidalgo, Sebastian Jose Teran. “Seborinos/Doubly_robust_nyr_2020.” GitHub, 16 Aug. 2020, github.com/Seborinos/doubly_robust_nyr_2020. Accessed 28 Apr. 2023.\nRothman, Andrew. “Doubly Robust Estimators for Causal Inference in Statistical Estimation.” Medium, 27 Dec. 2020, towardsdatascience.com/doubly-robust-estimators-for-causal-inference-in-statistical-estimation-3c00847e9db. Accessed 28 Apr. 2023.\nLunceford, Jared K., and Marie Davidian. “Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study.” Statistics in medicine 23.19 (2004): 2937-2960.\nZhong, Yongqi, et al. “AIPW: Augmented Inverse Probability Weighting.” R-Packages, 11 June 2021, cran.r-project.org/package=AIPW. Accessed 1 May 2023.\n\n\n\n\n",
      "last_modified": "2023-05-01T12:27:00-05:00"
    }
  ],
  "collections": []
}
