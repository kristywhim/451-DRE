{
  "articles": [
    {
      "path": "about.html",
      "title": "Introduction and Motivation",
      "author": [],
      "contents": "\nIntroduction\n“Correlation does not imply causation.” You might have heard this saying from your intro statistics course, and we knew if we’d like to find some evidence that makes us believe the causation. In causal inference, we will investigate the causal relationship between treatment (policy/ dosage/ drug/ habits, etc.) and the outcome of interest. By assigning people to different groups, we try to use various methods to reach the causal conclusion on which group has a better outcome? To do this, we should estimate the “causal effect”.\nA common way of estimating this is to calculate the average causal effect (ACE), denoted by:\n\\(E[Y^{a=1}]- E[Y^{a=0}]\\).\nIn this formula, a represents the potential treatment assignment: \\(a=0\\) means the individual will not be assigned treatment (control), and \\(a=1\\) dictates receiving treatment. In causal inference study, a huge blind spot is that after we observe the data, we want to know what would happen to an individual if they were to be assigned into the other group; unfortunately, this can never happen. As a result, we use capital \\(A\\) to represent the actual treatment received, and \\(a\\) for potential treatment under causal inference studies. \\(Y\\) is the outcome - it can be either quantitative or indicative. Combining together, the formula above makes sense: it records the average difference in the potential outcome between treatment and control group.\nIn statistics, after defining some particular interests and writing them out as mathematical formulas, researchers look for estimators to estimate the true parameter (in our case, that is the ACE). Doubly Robust Estimator (DRE) is a nice one due to its unbiasedness, meaning its average is equivalent to the true value of parameter (ACE). The reason it is called “doubly” is from the fact that DRE is composed of two different estimators: Inverse Probability Weighting (IPW), and Outcome Regression Model (REG). While this may not make any sense, don’t worry - in the next section, “Regression and IPW”, we will firstly go through these two regular, popular approaches in estimating ACE, and see how our doubly robust estimator serves to combine them and become even more powerful!\nMotivation of the project\nEstimating causal effects from data is a fundamental problem in many fields, including health care, economics, and many (social) sciences subjects. Xiang comes from an economic background whereas Kristy comes from a biology background. We teamed up and decided to explore this new, popular method, Doubly Robust estimation (DRE), which is widely used in biostatistics and econometric applications in many Difference-in-Difference (DiD, another way to say we are examining causal effects) experiments and causal inference contexts.\n\n\n\n",
      "last_modified": "2023-04-17T11:54:33-05:00"
    },
    {
      "path": "dre.html",
      "title": "Doubly Robust Estimator",
      "author": [],
      "contents": "\nDRE is a combined method from REG and IPW\nProperties of DRE\nProof of DRE’s unbiasedness\nWhen IPW is misspecified, but REG is correct\nThe first situation is that when we have IPW model\nmisspecified:\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}\\right) \\neq E\\left[Y^{a=1}\\right]\\\\\n\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right) \\neq E\\left[Y^{a=0}\\right]\n\\]\nBut our REG model is correct:\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n} \\hat{Y}_{i}^{a}=E\\left[Y^{a}\\right]\n\\]\nThen the true ACE will become:\n\\[\n\\scriptsize{\\begin{aligned}\nE\\left[\\widehat{\\left[D R E_{a=1}\\right.}-\\widehat{\\left. D R E_{a=0}\\right]}\\right] &= E\\left[\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\hat{Y}_{i}^{a=1}\\right)}{\\widehat{P S_{i}}}+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat{Y}_{i}^{a=0}\\right)}{1-{\\widehat PS_{i}}}+\\hat{Y}_{i}^{a=0}\\right)\\right] \\\\\n& =\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{A_{i}\\left(Y_{i}-\\hat Y_{i}^{a=1}\\right)}{\\widehat{PS_{i}}}+\\hat Y_{i}^{a=1}\\right)\\right]-\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat Y_{i}^{a=0}\\right)}{1-{\\widehat {PS}_{i}}}+\\hat{Y}^{a=0}\\right)\\right] \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{A_{i}\\left(Y_{i}-\\hat Y_{i}^{a=1}\\right)}{\\widehat {PS_{i}}}\\right]+E\\left[\\hat Y_{i}^{a=1}\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{\\left(1-A_{i}\\right)\\left(Y_{i}-\\hat Y_{i}^{a=0}\\right)}{1-{\\widehat P S_{i}}}\\right]+E\\left[\\hat Y_{i}^{a=0}\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat {PS_{i}}}\\right) E\\left[\\left [Y_{i}|A_{i}=1\\right)-E\\left[\\hat Y_{i}^{a=1}|A=1\\right]+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-{\\widehat {PS_{i}}}}\\right) E\\left[Y_i|A_{i}=0]-E[\\hat Y_{i}^{a=0}|A=0\\right]+\\hat{Y}_{i}^{a=0}\\right)\\right. \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{PS}_{i}}\\right)\\left(\\hat{Y}_{i}^{a=1}-\\hat{Y}_{i}^{a=1}\\right)+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{PS}_{i}}\\right)\\left(\\hat{Y}_{i}^{a=0}-\\hat{Y}_{i}^{a=0}\\right)+\\hat{Y}_{i}^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{PS}_{i}}\\right)\\left(0\\right)+\\hat{Y}_{i}^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{PS}_{i}}\\right)\\left(0\\right)+\\hat{Y}_{i}^{a=0}\\right) \\\\\n& =\\frac{\\sum_{i=1}^{n} \\hat{Y}_{i}^{a=1}}{n}-\\frac{\\sum_{i=1}^{n} \\hat{Y}_{i}^{a=0}}{n} \\\\\n& =E\\left[Y^{\\alpha=1}\\right]-E\\left[Y^{\\alpha=0}\\right]\n\\end{aligned}}\n\\]\nWhen REG is misspecified, but IPW is correct\nThe second situation is that when we have REG\nmodel misspecified: \\[\n\\frac{1}{n} \\sum_{i=1}^{n} \\hat{Y}_{i}^{a} \\neq E\\left[Y^{a}\\right]\n\\] But our IPW model is correct: \\[\n\\begin{aligned}\n& \\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S_i}}\\right)=E\\left[Y^{a=1}\\right] \\\\\n& \\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right)=E\\left[Y^{a=0}\\right] \\\\\n\\end{aligned}\n\\] First, let’s rearrange DRE’s formula a bit:\n\\[\n\\scriptsize{\n\\begin{aligned}\n\\widehat{D R E}_{a=1}-\\widehat{D R E}_{a=0}&=\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i\\left(Y_i-\\hat{Y}_i^{a=1}\\right)}{\\widehat{P S}_i}+\\hat{Y}_i^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right)\\left(Y_i-\\hat{Y}_i^{a=0}\\right)}{1-\\widehat{P S}_i}+\\hat{Y}_i^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\frac{A_i \\hat{Y}_i^{a=1}}{\\widehat{P S}_i}+\\hat{Y}_i^{a=1}\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\left(\\frac{\\left(1-A_i\\right) \\hat{Y}_i^{a=0}}{1-\\widehat{P S}_i}\\right)+\\hat{Y}_i^{a=0}\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S_i}}-\\left(\\frac{A_i \\widehat{Y}_i^{a=1}}{\\widehat{P S_i}}-\\widehat{Y}_i^{a=1}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S_i}}-\\left(\\frac{\\left(1-A_i\\right) \\hat{Y}_i^{a=0}}{1-\\widehat{P S_i}}-\\widehat{Y}_i^{a=0}\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\hat{Y}_i^{a=1}\\left(\\frac{A_i}{\\widehat{P S}_i}-1\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\hat{Y}_i^{a=0}\\left(\\frac{\\left(1-A_i\\right)}{1-\\widehat{P S_i}}-1\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{A_i Y_i}{\\widehat{P S}_i}-\\hat{Y}_i^{a=1}\\left(\\frac{A_i-\\widehat{P S}_i}{\\widehat{P S}_i}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^n\\left(\\frac{\\left(1-A_i\\right) Y_i}{1-\\widehat{P S}_i}-\\hat{Y}_i^{a=0}\\left(\\frac{\\left(1-A_i\\right)-\\left(1-\\widehat{P S}_i\\right)}{1-\\widehat{P S}_i}\\right)\\right) \\\\\n&\n\\end{aligned}}\n\\]\nThen the true ACE becomes: \\[\n\\scriptsize{\\begin{aligned}\nE\\left[\\widehat{D R E_{a=1}}-\\widehat{D R E_{a=0}}\\right]&=E\\left[\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{A_{i} Y_{i}}{\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S}_{i}}{\\widehat{P S}_{i}}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S} _{i}}\\right)\\right)\\right] \\\\\n& =\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{A_{i} Y_{i}}{\\widehat{P S_{i}}}-\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S_{i}}}{\\widehat{P S_{i}}}\\right)\\right)\\right]-\\frac{1}{n} E\\left[\\sum_{i=1}^{n}\\left(\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S}_{i}}-\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S_{i}}}\\right)\\right)\\right] \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{A_{i} Y_{i}}{\\widehat{P S}_{i}}\\right]-E\\left[\\hat{Y}_{i}^{a=1}\\left(\\frac{A_{i}-\\widehat{P S}_{i}}{\\widehat{P S} _{i}}\\right)\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(E\\left[\\frac{\\left(1-A_{i}\\right) Y_{i}}{1-\\widehat{P S} _{i}}\\right]-E\\left[\\hat{Y}_{i}^{a=0}\\left(\\frac{\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)}{1-\\widehat{P S_{i}}}\\right)\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right) E\\left[Y_{i}|A=1\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S_{i}}}\\right) E\\left[A_{i}-\\widehat{P S}_{i}\\right]\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S_{i}}}\\right) E\\left[Y_{i}|A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S_{i}}}\\right) E\\left[\\left(1-A_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)\\right]\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right)  E\\left[Y_{i}|A=1\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)\\left(E\\left[A_{i}\\right]-\\widehat{P S_{i}}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S}_{i}}\\right)  E\\left[Y_{i}|A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)\\left(E\\left[\\left(1-A_{i}\\right)\\right]-\\left(1-\\widehat{P S_{i}}\\right)\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{\\widehat{P S}_{i}}\\right) E\\left[Y_{i} \\mid A=1\\right]-\\left(\\frac{\\widehat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)\\left(\\widehat{P S}_{i}-\\widehat{P S}_{i}\\right)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\left(\\frac{1}{1-\\widehat{P S}_{i}}\\right) E\\left[Y_{i} \\mid A=0\\right]-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)\\left(\\left(1-\\widehat{P S}_{i}\\right)-\\left(1-\\widehat{P S_{i}}\\right)\\right)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}-\\left(\\frac{\\hat{Y}_{i}^{a=1}}{\\widehat{P S}_{i}}\\right)(0)\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}-\\left(\\frac{\\hat{Y}_{i}^{a=0}}{1-\\widehat{P S}_{i}}\\right)(0)\\right) \\\\\n& =\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=1\\right]}{\\widehat{P S}_{i}}\\right)-\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\frac{E\\left[Y_{i} \\mid A=0\\right]}{1-\\widehat{P S}_{i}}\\right) \\\\\n& =E\\left[Y^{a=1}\\right]-E\\left[Y^{a=0}\\right]\n\\end{aligned}}\n\\]\nIn either case, we prove that DRE’s unbiasedness\nin estimating the true average causal effects\nholds even though either of IPW/REG has been\nwrongly specified (but the other has to be\ncorrectly modeled). But it fails to work if both\ninverse-probability weighting model (IPW) and\noutcome regression model (REG) are incorrect.\n\n\n\n",
      "last_modified": "2023-04-17T11:54:34-05:00"
    },
    {
      "path": "index.html",
      "title": "Causal Inference: Doubly Robust Estimator",
      "description": "Welcome to the website. This website introduces Doubly Robust Estimator (DRE) in causal inference. This is a class project from course STAT 451: Causal Inference at Macalester College. The contents in this blog are collaborative efforts from Kristy Ma and Xiang Li.\n",
      "author": [],
      "contents": "\nTable of contents\nTo start exploring, please simply navigate to tabs on the upper right corner. We will start by introducing causal inference and motivation behind this project, then diving into mathematical aspect of Doubly Robust Estimator (DRE), and ending up with a simply computation simulation study. Have fun!\nIf you have any questions, please reach out to yma1@macalester.edu and xli2@macalester.edu. Thank you!\n\n\n\n",
      "last_modified": "2023-04-17T11:54:34-05:00"
    },
    {
      "path": "reg-ipw.html",
      "title": "Outcome Regression and Inverse Probability Weighting",
      "author": [],
      "contents": "\nPre DRE: Two common adjusting methods\nPreviously, we talked about two commonly used approaches for estimating ACE: outcome regression estimator (REG) and Inverse-Probability Weighting (IPW). When using outcome regression and IPW to estimate a causal effect, both methods are unbiased only if the statistical model is correctly specified- this requires our knowledge of predictors and guessing their associations with outcome correctly (which can be really difficult and impractical!). Let’s take a look at how they work.\nOutcome regression (REG)\nThe central idea about Outcome Regression Estimator (REG) is to cut off all non-causal paths between treatment variable A to outcome variable Y by applying the idea of Markov Assumption and D-separation in the causal graph (also known as directed acyclic graph, DAG).\nOutcome regression estimator is a statistical method used to estimate the relationship between treatment variables (A) and the outcome variable (Y). The outcome regression estimator can be used to make predictions about the outcome variable based on the values of the treatment variables, and it can also be used to test hypotheses about the relationship between the treatment variables and the outcome variable.\nThrough the Causal Markov Assumption the D-separation, the distributions of A and Y conditional on confounder set Z are conditionally independent. In this way, we successfully block association flow along non-causal paths because we have controlled the study units to share same values of Z before we compare them. This also means we have achieved conditionally exchangeability of the outcomes Y across treatment groups A. Therefore, now we are able to inspect within the subset of the data defined by Z and compare the average outcome (probability of Y) between the treatment groups A.\nThe mathematical formula expressing the REG model is: where we fit a linear regression on A and Z, \\(\\beta_1\\) will then become our estimation on average causal effect (ACE): it represents the change in the expected value of outcome Y when we compare a treatment unit to a control unit, assuming they share the same Z value.\n\\[\nE[Y|A,Z]=\\beta_0+\\beta_1A+\\beta_2Z\\\\\n\\hat \\beta_1=E[Y|A=1,Z]-E[Y|A=0,Z]=E[Y^{a=1}|Z]-E[Y^{a=0}|Z]\n\\]\nBy calculating Yi for each observation in every treatment condition, \\(A=1\\) and \\(A=0\\), we get the sample mean of outcome \\(E[Y^{A=a}]\\):\n\\[\nE[Y^{A=a}]=\\frac{1}{n} \\sum_{i=1}^n \\hat Y_i\n\\]\nWhen Z is both correctly identified and modeled, this is an unbiased estimate of the mean potential outcome had the entire population received treatment for all people (so both treatment and control groups).\nInverse Probability Weighting (IPW)\nThe central idea about IPW is to cut off the relationship between potential confounders Z to treatment variable A by reconstructing “pseudo population” from the data we have.\nInverse probability weighting (IPW) relies on the idea of building a logistic regression model that can be used to estimate the probability of being a treatment/ control unit observed for a particular observation (assuming that the confounders have been controlled). This predicted probability (after being converted from the output of the logistic regression model) is called propensity score in subsequent analyses. IPW is unique in measuring average causal effect by removing confounding variables using these weights.\nThis method is used under non-randomized trials (where the randomized trials are seen as the “gold standard” in causal studies): the number of people receiving treatment and control are not equal. As groups are imbalanced, we want to create a “pseudo-population” where half are treated and half are not treated.\nThis is achieved by re-weighting outcomes so that they reflect the global distribution of population sizes and help us to remove non-causal paths, thus leading to unbiased comparison. The weight for a particular Z group is the inverse of the propensity score, the probability of being assigned to the treatment/ control group, given patients attributes (Z).\n\\[\nWeight_{a=1}=\\frac{1}{P(A=1|Z)}=\\frac{1}{\\widehat {PS_i}}\nWeight_{a=0}=\\frac{1}{P(A=0|Z)}=\\frac{1}{1-\\widehat {PS_i}}\n\\]\nThis intuition can be reflected in the formula, where we adjust the formula by multiplying the propensity score, we end up getting the inverse probability weighting (IPW) formula:\n\\[\nP(Y|A=a)=\\sum_{i=1}^n P(Y|A=a, Z)P(Z)\\\\\nE[Y^{a=1}]=\\frac{1}{n}\\sum_{i=1}^n(\\frac {E[Y_i|A=1]}{\\widehat{PS_i}})\\\\\nE[Y^{a=0}]=\\frac{1}{n}\\sum_{i=1}^n(\\frac {E[Y_i|A=0]}{1-\\widehat{PS_i}})\\\\\nACE=E[Y^{a=1}]-E[Y^{a=0}]\n\\]\n\n\n\n",
      "last_modified": "2023-04-17T11:54:34-05:00"
    },
    {
      "path": "sim.html",
      "title": "Doubly Robust Estimation of Causal Effects in R",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\nComputational Simulation\nGoal: estimate a causal effect when you do not have data from a randomized experiment\nStrategy 1: Re-weighting each observation by the probability of receiving A or B so that the data approximates a randomized experiment\nStrategy 2: Modelling the outcome directly with a linear regression\nCombining Idea 1 and 2: To form doubly robust estimator\nSetting up data\nWe assign \\(X_1\\) and \\(X_2\\) as causal variables, and define a true ACE of 10.\n\n\nsimu_observational_data <- function(simu_id = 1, n_obs) {\n  X_1    <- rnorm(n_obs)\n  X_2    <- rnorm(n_obs)\n  XB     <- 0.2*X_1 + 0.2*X_2\n  prob_A <- exp(XB) / (1 + exp(XB))\n  A      <- rbinom(n_obs, 1, prob_A)\n  \n  # The causal effect of treatment A is 10\n  Y      <- 100 + X_1 + X_2 + 10*A + rnorm(n_obs) \n  \n  # summarize variables into a data frame\n  data.frame(simu_id = simu_id, n_obs = n_obs, \n             var_1 = X_1, var_2 = X_2, \n             treatment = A, outcome = Y)  \n} \n\n\nIPW model\n\n\nprop_score_model <- function(data) {\n  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')\n}\n\n\n\n\nprop_score_model_w <- function(data) {\n  # OOPS! I forgot var_2\n  glm(treatment ~ var_1, data = data, family = 'binomial')\n}\n\n\n\n\n#IPW correct\nipw_estimator <- function(data, model) {\n  data %>% \n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>% \n    summarise(\n      EY0_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EY1_ipw = mean(outcome*treatment / prob)\n    ) %>% \n    mutate(ipw = EY1_ipw - EY0_ipw)\n}\n\n\n\n\n# IPW wrong\nipw_estimator_w <- function(data, model) {\n  data %>% \n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>% \n    summarise(\n      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EYA_ipw = mean(outcome*treatment / prob)\n    ) %>% \n    mutate(ipw_w = EYA_ipw - EYB_ipw)\n}\n\n\nREG model\n\n\nmean_outcome_model <- function(data) {\n  glm(outcome ~ treatment + var_1 + var_2, data = data)\n}\n\n\n\n\nmean_outcome_model_w <- function(data) {\n  # MISSING var_2??!?!\n  glm(outcome ~ var_1 + treatment, data = data)\n}\n\n\n\n\n#REG correct\noutcome_model_estimator <- function(data) {\n   mean_model <- mean_outcome_model(data) # Compute the model\n   summary(mean_model)$coefficients['treatment', ][1] # Coefficient for treatment\n}\n\n\n\n\n# REG wrong\noutcome_model_estimator_w <- function(data) {\n   mean_model <- mean_outcome_model_w(data)\n   summary(mean_model)$coefficients['treatment', ][1]\n}\n\n\nDRE estimator\n\n\ndr_estimator <- function(data, prop_model, mean_model) {\n  data %>% \n    mutate(\n      prob = predict(prop_model, newdata = data, type = 'response'),\n      pred = predict(mean_model, newdata = data, type = 'response'),\n      augm = (treatment - prob)*pred\n    ) %>% \n    summarise(\n      EY0_dr = mean((outcome*(1 - treatment) - augm) / (1 - prob)),\n      EY1_dr = mean((outcome*treatment - augm) / prob)\n    ) %>% \n    mutate(dre = EY1_dr - EY0_dr)\n}\n\n\nNow, we have five models: IPW (both correct and incorrect), REG (both correct and incorrect), and DRE.\nStrategy 1: Inverse Probability Weighting (IPW)\nIntuition Behind it\nIn an experiment the probability of receiving a treatment are always equal across all units (i.e., 50%)\nIn the current case, the probability of receiving the treatment depends on variables that affect the outcome\nIf we knew what this probabilities are we could re-weight our sample such that the data would better match a randomized experiment\nIn the re-weighting scheme, units that were very likely to receive the treatment are weighted down and units that were very unlikely to receive the treatment are weighted up\nReminder: propensity score is just a logistic regression of the probability of receiving the treatment\nIn our example, we proposed the\n\n\nprop_score_model <- function(data) {\n  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')\n}\n\n\nStrategy 1: IPW estimator\nSimilar to a difference of means but weights each observation inversely proportional to its probability of receiving a treatment\n\\[\\widehat {PS}_i=\\pi(X_{i})\\]\n\\[\\hat{\\delta}_{IPW} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{Y_{i}A_{i}}{\\color{red}{\\pi(X_{i})}} - \\frac{Y_{i}(1-A_{i})}{\\color{red}{1-\\pi(X_{i})}}\\bigg]\\]\n\n\nipw_estimator <- function(data, model) {\n  data %>% \n    mutate(\n      prob = predict(model, newdata = data, type = 'response'),\n    ) %>% \n    summarise(\n      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\n      EYA_ipw = mean(outcome*treatment / prob)\n    ) %>% \n    mutate(ipw = EYA_ipw - EYB_ipw)\n}\n\n\nclass: center\n# IPW Performance\n\n\n\nIPW could fail\nIf the model for A is incorrect, it would cause bias in the IPW, which cause IPW to fail.\n\n\n\n\n\na <- ggplot(nested_df, aes(x=simu_id, y=ipw, group=1)) +\n  geom_boxplot()+\n  ylim(7, 13.5)\nb <- ggplot(nested_df, aes(x=simu_id, y=ipw_w, group=1))+\n  geom_boxplot()+\n  ylim(7, 13.5)\nplot_grid(a, b, labels=c(\"Correct IPW\", \"Incorrect IPW\"), ncol = 2, nrow = 1)\n\n\n\nWe overestimated the true ACE (which is 10) if we wrongly specified the model form in IPW setting.\nStrategy 2: REG estimator (model the outcome)\nDefault strategy of data scientist would be to create a linear model\n\\[Y =\\alpha_0 + \\alpha_1 X_1 + \\alpha_2 X_2 +\\delta A+ \\varepsilon\\]\nUse \\(\\hat{\\delta}\\) as the estimator of the causal effect\n\n\nmean_outcome_model <- function(data) {\n  glm(outcome ~ var_1 + var_2 + treatment, data = data)\n}\n\n\n\n\noutcome_model_estimator <- function(data) {\n   mean_model <- mean_outcome_model(data)\n   summary(mean_model)$coefficients['treatment', ][1]\n}\n\n\nclass: center\n# Strategy 2: Performance - Simulation\n\n\n\nREG model could also fail\nIf the model for Y is incorrect (as we recalled we left var_2 out), it would cause bias in the REG outcome model, which cause the model to fail.\n\n\nmean_model_estimator_w <- \n  mean(nested_df$model_estimate_w)\n\nnested_df %>% \n  ggplot(aes(x = simu_id, y = model_estimate_w)) +\n  ggtitle(paste('The mean of the REG estimate (incorrectly specified) is ', round(mean_model_estimator_w, 2))) + \n  geom_point(color = 'blue') +\n  geom_hline(yintercept = 10) +\n  theme_bw()\n\n\n\n\n\nc <- ggplot(nested_df, aes(x=simu_id, y=model_estimate, group=1)) +\n  geom_boxplot()+\n  ylim(9, 11)\nd <- ggplot(nested_df, aes(x=simu_id, y=model_estimate_w, group=1))+\n  geom_boxplot()+\n  ylim(9, 11)\nplot_grid(c, d, labels=c(\"Correct REG\", \"Incorrect REG\"), ncol = 2, nrow = 1)\n\n\n\n\nWe also overestimated the true ACE (10) if our REG model is mis-specified.\n\n\n---\n\n# Combining Strategy 1 and 2\n\n--\n\n- If the propensity score model is incorrect, strategy 1 will not work\n\n--\n\n- If the outcome model is incorrect, strategy 2 will not work\n\n--\n\n- If you combine both approaches, you just need either one to work but not both\n\n--\n\n- As a data scientist you have 1 out of 2 chances to get the correct answer\n\n--\n\n- This is called the doubly robustness property\n\n---\n\n# This could also fail but is less likely to do so\n\n\n---\n\n# Combining Strategy 1 and 2 - Doubly Robust Estimator\n\n$$\\hat{\\delta}_{DR} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{Y_{i}A_{i} -\\color{red}{(A_i-\\pi(X_{i}))\\mu(X_i, A_i)}}{\\pi(X_{i})} - \\frac{Y_{i}(1-A_{i}) -\\color{red}{(A_i-\\pi(X_{i}))\\mu(X_i, A_i)}}{1-\\pi(X_{i})}\\bigg]$$\n\nwhere $$\\mu(X, A) = \\hat{\\alpha}_0 + \\hat{\\alpha}_1 X_1 + \\hat{\\alpha}_2 X_2 +\\hat{\\delta} A$$\n\n- The term in red is said to *augment* the IPW estimator\n\n- It can be shown that this estimator will consistently estimate $\\delta = E[Y(A)]-E[Y(B)]$ as long as either $\\pi(X_{i})$ or $\\mu(X, A)$ are correct \n\n---\n\n# Combining Strategy 1 and 2 - Doubly Robust Estimator\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<div class=\"sourceCode\"><pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span><span class='va'>dr_estimator<\/span> <span class='op'>&lt;-<\/span> <span class='kw'>function<\/span><span class='op'>(<\/span><span class='va'>data<\/span>, <span class='va'>prop_model<\/span>, <span class='va'>mean_model<\/span><span class='op'>)<\/span> <span class='op'>{<\/span><\/span>\n<span>  <span class='va'>data<\/span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%<\/a><\/span> <\/span>\n<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate<\/a><\/span><span class='op'>(<\/span><\/span>\n<span>      prob <span class='op'>=<\/span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict<\/a><\/span><span class='op'>(<\/span><span class='va'>prop_model<\/span>, newdata <span class='op'>=<\/span> <span class='va'>data<\/span>, type <span class='op'>=<\/span> <span class='st'>'response'<\/span><span class='op'>)<\/span>,<\/span>\n<span>      pred <span class='op'>=<\/span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict<\/a><\/span><span class='op'>(<\/span><span class='va'>mean_model<\/span>, newdata <span class='op'>=<\/span> <span class='va'>data<\/span>, type <span class='op'>=<\/span> <span class='st'>'response'<\/span><span class='op'>)<\/span>,<\/span>\n<span>      augm <span class='op'>=<\/span> <span class='op'>(<\/span><span class='va'>treatment<\/span> <span class='op'>-<\/span> <span class='va'>prob<\/span><span class='op'>)<\/span><span class='op'>*<\/span><span class='va'>pred<\/span><\/span>\n<span>    <span class='op'>)<\/span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%<\/a><\/span> <\/span>\n<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/summarise.html'>summarise<\/a><\/span><span class='op'>(<\/span><\/span>\n<span>      EYB_dr <span class='op'>=<\/span> <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean<\/a><\/span><span class='op'>(<\/span><span class='op'>(<\/span><span class='va'>outcome<\/span><span class='op'>*<\/span><span class='op'>(<\/span><span class='fl'>1<\/span> <span class='op'>-<\/span> <span class='va'>treatment<\/span><span class='op'>)<\/span> <span class='op'>-<\/span> <span class='va'>augm<\/span><span class='op'>)<\/span> <span class='op'>/<\/span> <span class='op'>(<\/span><span class='fl'>1<\/span> <span class='op'>-<\/span> <span class='va'>prob<\/span><span class='op'>)<\/span><span class='op'>)<\/span>,<\/span>\n<span>      EYA_dr <span class='op'>=<\/span> <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean<\/a><\/span><span class='op'>(<\/span><span class='op'>(<\/span><span class='va'>outcome<\/span><span class='op'>*<\/span><span class='va'>treatment<\/span> <span class='op'>-<\/span> <span class='va'>augm<\/span><span class='op'>)<\/span> <span class='op'>/<\/span> <span class='va'>prob<\/span><span class='op'>)<\/span><\/span>\n<span>    <span class='op'>)<\/span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%<\/a><\/span> <\/span>\n<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate<\/a><\/span><span class='op'>(<\/span>dre <span class='op'>=<\/span> <span class='va'>EYA_dr<\/span> <span class='op'>-<\/span> <span class='va'>EYB_dr<\/span><span class='op'>)<\/span><\/span>\n<span><span class='op'>}<\/span><\/span><\/code><\/pre><\/div>\n\n<\/div>\n\n\n---\n\nclass: center\n# DRE Performance\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<img src=\"sim_files/figure-html5/unnamed-chunk-23-1.png\" width=\"624\" />\n\n<\/div>\n\n\n\n---\n\n# Doubly Robust Estimator - Propensity Score is Incorrect\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<div class=\"sourceCode\"><pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span><span class='va'>prop_score_model<\/span> <span class='op'>&lt;-<\/span> <span class='kw'>function<\/span><span class='op'>(<\/span><span class='va'>data<\/span><span class='op'>)<\/span> <span class='op'>{<\/span><\/span>\n<span>  <span class='co'># OOPS! I forgot var_2<\/span><\/span>\n<span>  <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm<\/a><\/span><span class='op'>(<\/span><span class='va'>treatment<\/span> <span class='op'>~<\/span> <span class='va'>var_1<\/span>, data <span class='op'>=<\/span> <span class='va'>data<\/span>, family <span class='op'>=<\/span> <span class='st'>'binomial'<\/span><span class='op'>)<\/span><\/span>\n<span><span class='op'>}<\/span><\/span><\/code><\/pre><\/div>\n\n<\/div>\n\n\n---\n\nclass: center\n# Doubly Robust Estimator - Propensity Score is Incorrect\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n\n\n<\/div>\n\n\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<img src=\"sim_files/figure-html5/unnamed-chunk-26-1.png\" width=\"60%\" />\n\n<\/div>\n\n\n---\n# Doubly Robust Estimator - Mean Model is Incorrect\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<div class=\"sourceCode\"><pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span><span class='va'>mean_outcome_model<\/span> <span class='op'>&lt;-<\/span> <span class='kw'>function<\/span><span class='op'>(<\/span><span class='va'>data<\/span><span class='op'>)<\/span> <span class='op'>{<\/span><\/span>\n<span>  <span class='co'># HOW COULD I FORGOTTEN var_2??!?! I AM SO DUMB!<\/span><\/span>\n<span>  <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm<\/a><\/span><span class='op'>(<\/span><span class='va'>outcome<\/span> <span class='op'>~<\/span> <span class='va'>var_1<\/span> <span class='op'>+<\/span> <span class='va'>treatment<\/span>, data <span class='op'>=<\/span> <span class='va'>data<\/span><span class='op'>)<\/span><\/span>\n<span><span class='op'>}<\/span><\/span><\/code><\/pre><\/div>\n\n<\/div>\n\n\n---\n<!-- class: center -->\n# Doubly Robust Estimator - Mean Model is Incorrect\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n\n\n<\/div>\n\n\n<div class=\"layout-chunk\" data-layout=\"l-body\">\n<img src=\"sim_files/figure-html5/unnamed-chunk-29-1.png\" width=\"60%\" />\n\n<\/div>\n\n\n---\n# Conclusion\n\n- If you have non randomized data you cannot simply calculate the difference in means between $A$\n and $B$ to estimate the causal effect\n \n- You can use the IPW estimator based on a logistic regression of the probability of receiving the treatment\n\n- You can model the outcome based on a linear regression with the confounding variables as well as $A$\n\n- Or you can use the doubly robust estimator which will work as long as either the logistic or the linear regression are correct, but not both\n\n---\n# References\n\n- Lunceford, Jared K., and Marie Davidian. \"Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study.\" Statistics in medicine 23.19 (2004): 2937-2960.\n\n```{.r .distill-force-highlighting-css}\n\n\n",
      "last_modified": "2023-04-17T11:55:07-05:00"
    },
    {
      "path": "wrapup.html",
      "title": "Wrap-up and Conclusion",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\nTitle\n\n\n\n",
      "last_modified": "2023-04-17T11:54:45-05:00"
    }
  ],
  "collections": []
}
