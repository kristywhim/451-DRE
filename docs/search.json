{
  "articles": [
    {
      "path": "about.html",
      "title": "Introduction and Motivation",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\nIntroduction\r\nMotivation of the project\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-02T18:59:11-05:00"
    },
    {
      "path": "dre.html",
      "title": "Doubly Robust Estimator",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\nDRE is a combined method from REG and IPW\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-02T18:59:12-05:00"
    },
    {
      "path": "index.html",
      "title": "Causal Inference: Doubly Robust Estimator",
      "description": "Welcome to the website. This website introduces Doubly Robust Estimator (DRE) in causal inference. This is a class project from course STAT 451: Causal Inference at Macalester College. The contents in this blog are collaborative efforts from Kristy Ma and Xiang Li.\n",
      "author": [],
      "contents": "\r\nTable of contents\r\nTo start exploring, please simply navigate to tabs on the upper right corner. We will start by introducing causal inference and motivation behind this project, then diving into mathematical aspect of Doubly Robust Estimator (DRE), and ending up with a simply computation simulation study. Have fun!\r\nIf you have any questions, please reach out to yma1@macalester.edu and xli2@macalester.edu. Thank you!\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-02T18:59:13-05:00"
    },
    {
      "path": "reg-ipw.html",
      "title": "Outcome Regression and Inverse Probability Weighting",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\nPre DRE: Two common adjusting methods\r\nOutcome regression (REG)\r\nInverse Probability Weighting (IPW)\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-02T18:59:13-05:00"
    },
    {
      "path": "sim.html",
      "title": "Doubly Robust Estimation of Causal Effects in R",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\nComputational Simulation\r\nWhat is Causal Inference in Data Science?\r\n–\r\nA/B tests are great at allowing us to reach causal claims\r\n–\r\nWill A or B cause a better outcome? (i.e, will A cause a bigger client retention than B)\r\n–\r\nSometimes we have data on A and B but not generated through a random experiment\r\n–\r\nRelying solely on this data won’t allow you to make correct causal claims about A and B\r\n–\r\nWe can use causal inference methods to try to estimate the causal effect of using A versus B even from a non random experiment\r\nWhat is this talk about?\r\n–\r\nGoal: estimate a causal effect when you do not have data from a randomized experiment\r\n–\r\nStrategy 1: Re weighting each observation by the probability of receiving A or B so that the data approximates a randomized experiment\r\n–\r\nStrategy 2: Modelling the outcome directly with a linear regression\r\n–\r\nCombining Idea 1 and 2: To form doubly robust estimator\r\nWhat is a causal effect?\r\nConterfactual difference: On average receiving treatment \\(A\\) compared to \\(B\\) will cause a difference in the outcome of \\(\\delta\\)\r\n\\[\\delta = E[Y(A)] - E[Y(B)]\\]\r\nwhere \\(Y(A)\\) is the outcome if treatment \\(A\\) had been received, and \\(Y(B)\\) is the outcome if treatment \\(B\\) had been received.\r\nMean difference: The average difference in outcomes between those receiving \\(A\\) and \\(B\\)\r\n\\[E[Y|A] - E[Y|B]\\]\r\nIn an A/B test we can estimate the causal effect \\(\\delta\\) by a simple difference of means because of randomization\r\n\\[E[Y|A] - E[Y|B] = E[Y(A)] - E[Y(B)]\\]\r\nIn non randomized data this is not necessarily true\r\n\\[E[Y|A] - E[Y|B] \\neq E[Y(A)] - E[Y(B)]\\]\r\nA non randomized data simulation\r\n–\r\n\r\n\r\nsimu_observational_data <- function(n_obs) {\r\n  X_1    <- rnorm(n_obs)\r\n  X_2    <- rnorm(n_obs)\r\n  XB     <- 0.25*X_1 + 0.25*X_2\r\n  prob_A <- exp(XB) / (1 + exp(XB)) # This is not an A/B test!\r\n  A      <- rbinom(n_obs, 1, prob_A) # This is not an A/B test!\r\n  \r\n  # The causal effect of receiving A is 10\r\n  Y      <- 100 + X_1 + X_2 + 10*A + rnorm(n_obs)  \r\n  \r\n  data.frame(var_1 = X_1, var_2 = X_2, treatment = A, outcome = Y)  \r\n} \r\n\r\n\r\n–\r\nIn this case \\(\\delta = E[Y(A)] - E[Y(B)] = 10\\)\r\n–\r\nUnlike a random experiment, the probability of receiving treatment A depends on X_1 and X_2\r\n–\r\nThis makes it difficult to to estimate the causal effect\r\nA non randomized experiment\r\nHow is is different from an experiment or A/B-test?\r\n\r\n\r\n# Replace this\r\nprob_A <- exp(XB) / (1 + exp(XB)) # This is not an A/B test!\r\nA      <- rbinom(n_obs, 1, prob_A) # This is not an A/B test!\r\n# With this\r\nA      <- rbinom(n_obs, 1, 0.5) # This is an A/B =)\r\n\r\n\r\nNaive estimator\r\n–\r\nNaive estimator is the difference between the mean of the treatment \\(A\\) and \\(B\\)\r\n\\[\\hat{\\delta}_{Naive} = \\frac{1}{n}\\sum_{i=1}^{n}\\Big[Y_{i}A_{i} - Y_{i}(1-A_{i})\\Big]\\]\r\n–\r\nWe are trying to estimate this\r\n\\[\\delta = E[Y(A)] - E[Y(B)]\\]\r\n–\r\n\r\n\r\nnaive_estimator <- function(data) {\r\n  data %>% \r\n    summarise(\r\n      EYB_naive = mean(outcome*(1 - treatment)),\r\n      EYA_naive = mean(outcome*treatment)\r\n    ) %>% \r\n    mutate(naive_estimator = EYA_naive- EYB_naive)\r\n}\r\n\r\n\r\nNaive estimator fails in this case\r\n–\r\nThe difference of means does not capture exclusively the effect of A on the outcome but mixes in effects from other variables as well\r\nclass: center\r\nNaive estimator fails in this case\r\n\r\n\r\n\r\nStrategy 1: Inverse Probability Weighting\r\nIntuition Behind it\r\n–\r\nIn an experiment the probability of receiving a treatment are always equal across all units (i.e., 50%)\r\n–\r\nIn the current case, the probability of receiving the treatment depends on variables that affect the outcome\r\n–\r\nIf we knew what this probabilities are we could reweight our sample such that the data would better match a randomized experiment\r\n–\r\nIn the reweighting scheme, units that were very likely to receive the treatment are weighted down and units that were very unlikely to receive the treatment are weighted up\r\nStrategy 1: Inverse Probability Weighting - Propensity Score\r\n–\r\nHow do we estimate these probabilities?\r\n–\r\nThe propensity score is just a logistic regression of the probability of receiving the treatment\r\n–\r\n\r\n\r\nprop_score_model <- function(data) {\r\n  glm(treatment ~ var_1 + var_2, data = data, family = 'binomial')\r\n}\r\n\r\n\r\nIt is just a fancy name for logistic regression to sound smart at conferences!\r\nStrategy 1: IPW Estimator\r\nSimilar to a difference of means but weights each observation inversely proportional to its probability of receiving a treatment\r\n\\[\\hat{\\delta}_{IPW} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{Y_{i}A_{i}}{\\color{red}{\\pi(X_{i})}} - \\frac{Y_{i}(1-A_{i})}{\\color{red}{1-\\pi(X_{i})}}\\bigg]\\]\r\n\r\n\r\nipw_estimator <- function(data, model) {\r\n  data %>% \r\n    mutate(\r\n      prob = predict(model, newdata = data, type = 'response'),\r\n    ) %>% \r\n    summarise(\r\n      EYB_ipw = mean(outcome*(1 - treatment) / (1 - prob)),\r\n      EYA_ipw = mean(outcome*treatment / prob)\r\n    ) %>% \r\n    mutate(ipw = EYA_ipw - EYB_ipw)\r\n}\r\n\r\n\r\nclass: center\r\n# IPW Performance\r\n\r\n\r\n\r\nIPW could fail\r\n\r\n\r\nprop_score_model <- function(data) {\r\n  # OOPS! I forgot var_2\r\n  glm(treatment ~ var_1, data = data, family = 'binomial')\r\n}\r\n\r\n\r\nStrategy 2: Model the Outcome\r\nDefault strategy of data scientist would be to create a linear model\r\n\\[Y =\\alpha_0 + \\alpha_1 X_1 + \\alpha_2 X_2 +\\delta A+ \\varepsilon\\]\r\nUse \\(\\hat{\\delta}\\) as the estimator of the causal effect\r\n\r\n\r\nmean_outcome_model <- function(data) {\r\n  glm(outcome ~ var_1 + var_2 + treatment, data = data)\r\n}\r\n\r\n\r\n\r\n\r\noutcome_model_estimator <- function(data) {\r\n   mean_model <- mean_outcome_model(data)\r\n   summary(mean_model)$coefficients['treatment', ][1]\r\n}\r\n\r\n\r\nclass: center\r\n# Strategy 2: Performance - Simulation\r\n\r\n\r\n\r\nOutcome model could also fail\r\n\r\n\r\nmean_outcome_model <- function(data) {\r\n  # HOW COULD I FORGOTTEN var_2??!?! I AM SO DUMB!\r\n  glm(outcome ~ var_1 + treatment, data = data)\r\n}\r\n\r\n\r\nCombining Strategy 1 and 2\r\n–\r\nIf the propensity score model is incorrect, strategy 1 will not work\r\n–\r\nIf the outcome model is incorrect, strategy 2 will not work\r\n–\r\nIf you combine both approaches, you just need either one to work but not both\r\n–\r\nAs a data scientist you have 1 out of 2 chances to get the correct answer\r\n–\r\nThis is called the doubly robustness property\r\nThis could also fail but is less likely to do so\r\nCombining Strategy 1 and 2 - Doubly Robust Estimator\r\n\\[\\hat{\\delta}_{DR} = \\]\r\n\\[\\frac{1}{n}\\sum_{i=1}^{n}\\bigg[\\frac{Y_{i}A_{i} -\\color{red}{(A_i-\\pi(X_{i}))\\mu(X_i, A_i)}}{\\pi(X_{i})} - \\frac{Y_{i}(1-A_{i}) -\\color{red}{(A_i-\\pi(X_{i}))\\mu(X_i, A_i)}}{1-\\pi(X_{i})}\\bigg]\\]\r\nwhere \\[\\mu(X, A) = \\hat{\\alpha}_0 + \\hat{\\alpha}_1 X_1 + \\hat{\\alpha}_2 X_2 +\\hat{\\delta} A\\]\r\nThe term in red is said to augment the IPW estimator\r\nIt can be shown that this estimator will consistently estimate \\(\\delta = E[Y(A)]-E[Y(B)]\\) as long as either \\(\\pi(X_{i})\\) or \\(\\mu(X, A)\\) are correct\r\nCombining Strategy 1 and 2 - Doubly Robust Estimator\r\n\r\n\r\ndr_estimator <- function(data, prop_model, mean_model) {\r\n  data %>% \r\n    mutate(\r\n      prob = predict(prop_model, newdata = data, type = 'response'),\r\n      pred = predict(mean_model, newdata = data, type = 'response'),\r\n      augm = (treatment - prob)*pred\r\n    ) %>% \r\n    summarise(\r\n      EYB_dr = mean((outcome*(1 - treatment) - augm) / (1 - prob)),\r\n      EYA_dr = mean((outcome*treatment - augm) / prob)\r\n    ) %>% \r\n    mutate(dre = EYA_dr - EYB_dr)\r\n}\r\n\r\n\r\nclass: center\r\n# DRE Performance\r\n\r\n\r\n\r\nDoubly Robust Estimator - Propensity Score is Incorrect\r\n\r\n\r\nprop_score_model <- function(data) {\r\n  # OOPS! I forgot var_2\r\n  glm(treatment ~ var_1, data = data, family = 'binomial')\r\n}\r\n\r\n\r\nclass: center\r\n# Doubly Robust Estimator - Propensity Score is Incorrect\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Doubly Robust Estimator - Mean Model is Incorrect\r\n\r\n# Doubly Robust Estimator - Mean Model is Incorrect\r\n\r\n\r\n\r\n\r\nConclusion\r\nIf you have non randomized data you cannot simply calculate the difference in means between \\(A\\)\r\nand \\(B\\) to estimate the causal effect\r\nYou can use the IPW estimator based on a logistic regression of the probability of receiving the treatment\r\nYou can model the outcome based on a linear regression with the confounding variables as well as \\(A\\)\r\nOr you can use the doubly robust estimator which will work as long as either the logistic or the linear regression are correct, but not both\r\nReferences\r\nLunceford, Jared K., and Marie Davidian. “Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study.” Statistics in medicine 23.19 (2004): 2937-2960.\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-02T18:59:31-05:00"
    },
    {
      "path": "wrapup.html",
      "title": "Wrap-up and Conclusion",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\nTitle\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-02T18:59:32-05:00"
    }
  ],
  "collections": []
}
